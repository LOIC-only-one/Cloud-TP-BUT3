## MODULE 1 : FONDAMENTAUX DU CLOUD COMPUTING

## Support de Cours √âtudiant ‚Äì Licence 3 BUT R&T
**Date :** Janvier 2026  

---

## TABLE DES MATI√àRES

1. Qu'est-ce que le Cloud Computing ?
2. Les 5 Caract√©ristiques Essentielles (NIST)
3. Mod√®le de Responsabilit√© Partag√©e
4. Les Trois Mod√®les de D√©ploiement
5. Classification des Services Cloud
6. Tendances 2024-2026 : Edge, FinOps, Souverainet√©
7. Matrice de S√©lection D√©cisionnelle

---

## CHAPITRE 1 : QU'EST-CE QUE LE CLOUD COMPUTING ?

### 1.1 D√©finition Fondamentale

Le **cloud computing** (informatique en nuage) est un mod√®le r√©volutionnaire de fourniture de ressources informatiques ‚Äî serveurs, stockage, bases de donn√©es, logiciels ‚Äî √† travers Internet, **sur demande et sans besoin de d√©tenir physiquement l'infrastructure**.

**D√©finition NIST SP 800-145 (2011, actualis√©e 2024) :**
> Le cloud computing est un mod√®le permettant un acc√®s √† un ensemble partag√© de ressources informatiques configurables (r√©seaux, serveurs, stockage, applications, services) qui peut √™tre rapidement approvisionn√© et lib√©r√© avec un effort de gestion minimal ou une interaction du fournisseur de services.

### 1.2 √âvolution Historique et Contexte

| P√©riode       | √âv√©nement                                       | Impact                                 |
| ------------- | ----------------------------------------------- | -------------------------------------- |
| **2000-2005** | Virtualisation mat√©rielle √©merge                | Infrastructure d√©compos√©e              |
| **2006**      | AWS lance EC2                                   | Premier service IaaS commercial viable |
| **2008-2012** | Adoption massive SaaS (Salesforce, Google Apps) | Cloud devient mainstream               |
| **2015-2020** | Conteneurs (Docker) et Kubernetes               | Architecture cloud-native normalis√©e   |
| **2020-2024** | Multi-cloud courant ; FinOps √©merge             | Optimisation co√ªts critique            |
| **2024-2026** | Edge Computing + IA distribu√©e                  | Calcul rapproch√© donn√©es essentielles  |

### 1.3 Pourquoi le Cloud ? Quatre Moteurs √âconomiques

#### 1Ô∏è‚É£ **R√©duction des Co√ªts Initiaux (CAPEX ‚Üí OPEX)**

**Avant (Datacenter On-Premise) :**
- Investissement initial : 500k‚Ç¨-2M‚Ç¨ pour serveurs
- Temps acquisition : 3-4 mois (achat, livraison, installation)
- Utilisation : souvent <30% capacit√© moyenne (surprovisionnement)
- Risque : Si demande < pr√©vision, mat√©riel inutilis√© = perte

**Avec Cloud Public :**
- Investissement initial : 0‚Ç¨
- Temps acquisition : 5 minutes (interface web)
- Utilisation : scaling √† la demande exactement
- Flexibilit√© : Augmenter/r√©duire selon pics r√©els

**Exemple Num√©rique :**
```
Startup Web 10 d√©veloppeurs

Sc√©nario On-Premise :
  ‚Ä¢ Serveurs : 200k‚Ç¨
  ‚Ä¢ R√©seau : 30k‚Ç¨
  ‚Ä¢ Personnel IT : 50k‚Ç¨/an
  ‚Ä¢ √âlectricit√© : 12k‚Ç¨/an
  ‚Ä¢ 1√®re ann√©e : 292k‚Ç¨ CAPEX + OPEX

Sc√©nario Cloud :
  ‚Ä¢ Serveurs : 0‚Ç¨ CAPEX
  ‚Ä¢ Infrastructure : 3k‚Ç¨/mois OPEX = 36k‚Ç¨/an
  ‚Ä¢ Personnel IT : 0‚Ç¨ (moins d'ops)
  ‚Ä¢ 1√®re ann√©e : 36k‚Ç¨
  
√âconomie : 256k‚Ç¨ (88% r√©duction co√ªts ann√©e 1)
```

#### 2Ô∏è‚É£ **Scalabilit√© √âlastique**

| Situation | Datacenter | Cloud |
|-----------|-----------|-------|
| Charge normale (100 req/s) | 5 serveurs actifs | 3 instances = 300‚Ç¨/mois |
| Pic (500 req/s, 2h) | Impossible sans achat | 15 instances = 1500‚Ç¨ pour 2h |
| Apr√®s pic | Capacit√© inutile 4-5 serveurs | Z√©ro instances = 0‚Ç¨ |
| Gestion | Technique ET risque business | Automatis√© par r√®gles |

**Implication :** E-commerce peut g√©rer pics No√´l sans investir dans mat√©riel.

#### 3Ô∏è‚É£ **Agilit√© et Time-to-Market**

**Temps d√©ploiement :**
- On-premise : 3-4 mois
- Cloud public : **5 minutes**

**Implication pour startup :** Valider hypoth√®se business en semaines, pas trimestres.

#### 4Ô∏è‚É£ **Acc√®s √† Expertise Globale**

En cloud public, vous utilisez services g√©r√©s (bases de donn√©es, machine learning, streaming temps r√©el) que petite √©quipe ne pourrait jamais construire et maintenir seule.

**Exemple :** Utiliser Google Cloud BigQuery pour analytics distribu√©es vs. recruter 5 data engineers.

---

## CHAPITRE 2 : LES 5 CARACT√âRISTIQUES ESSENTIELLES (NIST)

### 2.1 Self-Service √† la Demande

**D√©finition :** L'utilisateur approvisionne ressources informatiques **24/7 sans intervention manuelle** du fournisseur, via interface web ou API.

**Caract√©ristiques :**
- ‚úÖ Cr√©ation instances, stockage, bases de donn√©es en minutes
- ‚úÖ Modification/suppression sans processus administratif
- ‚úÖ Acc√®s 24/7 ind√©pendant horaires support IT
- ‚úÖ Automatisation par API (Infrastructure as Code)

**Exemple Concret :**
> Vous √™tes d√©veloppeur, 14h un samedi. Vous avez besoin de 3 serveurs web pour test charge. 
> - Datacenter : Appel hotline IT (ferm√©e), attendre lundi, processus 2 jours
> - Cloud AWS : Console web ‚Üí Click "Launch 3 instances" ‚Üí 5 minutes ‚Üí Online
> 
> Flexibilit√© = productivit√©

**Implication P√©dagogique :** √âtudiants deviennent **op√©rationnels imm√©diatement** sans d√©pendre de l‚ÄôIT.

### 2.2 Acc√®s R√©seau Large

**D√©finition :** Les services cloud sont accessibles via **r√©seau standard (Internet)** sur **tous types appareils**.

**Appareils Support√©s :**
- PC bureau (Windows, macOS, Linux)
- Tablettes (iPad, Android)
- Smartphones
- Objets IoT (capteurs, routeurs)
- Montres connect√©es

**Exemple ‚Äî Google Workspace :**
```
09:00 - Paris, Bureau, PC Windows
       Edit Google Sheet "Budget Q1"

11:00 - Avion, iPad
       Continue edit = donn√©es synchro temps r√©el

17:00 - M√©tro, Smartphone
       V√©rifier le sheet = donn√©es √† jour

‚Üí Z√âRO synchronisation manuelle, acc√®s ubiquitaire
```

**Implication :** Mobilit√© compl√®te, travail hybride transparent.

### 2.3 Mutualisation des Ressources (Resource Pooling)

**D√©finition :** Les ressources physiques **sont partag√©es entre plusieurs clients** (multi-tenancy), avec allocation dynamique selon la demande.

**Illustration Architecturale :**

```
Serveurs Physiques AWS eu-west-1 (Irlande)

Serveur Physique 1 (Intel Xeon, 64GB RAM)
‚îú‚îÄ Client A : Instance VM_1 (2 vCPU, 8GB RAM)
‚îú‚îÄ Client B : Instance VM_2 (4 vCPU, 16GB RAM)
‚îú‚îÄ Client C : Instance VM_3 (2 vCPU, 8GB RAM)
‚îî‚îÄ Slack disponible : 2 vCPU, 32GB RAM

‚Üì HEURE 14H (Pic pour Client B)

Serveur Physique 1
‚îú‚îÄ Client A : Instance VM_1 (2 vCPU, 8GB RAM) ‚Äî r√©duite
‚îú‚îÄ Client B : Instance VM_2b (6 vCPU, 20GB RAM) ‚Äî augment√©e
‚îú‚îÄ Client B : Instance VM_2c (2 vCPU, 4GB RAM) ‚Äî NOUVELLE
‚îú‚îÄ Client C : Instance VM_3 (2 vCPU, 8GB RAM)
‚îî‚îÄ Slack : 0 vCPU
```

**Avantage √âconomique :** AWS peut facturer 1000 clients sur 100 serveurs, car **statistiquement jamais tous les clients simultan√©ment au maximum**. Math√©matique d'√©conomies d'√©chelle.

**Implication S√©curit√© :** 
- ‚úÖ Donn√©es Client A et Client B sur M√äME serveur physique
- ‚úÖ Hyperviseur (Xen/KVM) isole cependant les machines virtuelles
- ‚ö†Ô∏è Th√©oriquement, failles hyperviseur (tr√®s rares) pourraient permettre saut inter-VM
- ‚úÖ Mitigation : chiffrement donn√©es en transit + at-rest

**Concept Cl√© :** Resource pooling = profit margin AWS possible.

### 2.4 √âlasticit√© Rapide

**D√©finition :** **Augmentation/r√©duction automatique** des capacit√©s en fonction de la demande, par r√®gles ou manuelle.

**M√©canisme (Auto-scaling):**
```
R√®gle d√©finie : "Si average CPU > 70% pendant 2 min ‚Üí +1 serveur"
                "Si average CPU < 20% pendant 5 min ‚Üí -1 serveur"

Timeline:
09:00 - Charge normale
        ‚îú‚îÄ 2 serveurs web
        ‚îú‚îÄ CPU avg : 45%
        ‚îî‚îÄ Co√ªt : 500‚Ç¨/mois

12:00 - Lunch peak
        ‚îú‚îÄ CPU avg : 82% (D√âCLENCHE r√®gle +1)
        ‚îú‚îÄ 3 serveurs web (auto-add)
        ‚îî‚îÄ CPU retombe 65%

12:05 - Pic disparu
        ‚îú‚îÄ CPU avg : 25% (D√âCLENCHE r√®gle -1)
        ‚îú‚îÄ 2 serveurs web (auto-remove)
        ‚îî‚îÄ Co√ªt revient 500‚Ç¨/mois
```

**Cas d'Usage R√©el : E-Commerce Pic No√´l**

| P√©riode | Serveurs | Co√ªt Mensuel | Notes |
|---------|----------|-------------|-------|
| Janvier-Octobre | 5 serveurs | 1500‚Ç¨ | Load normal |
| Novembre-D√©cembre | Auto-scale √† 30 | 9000‚Ç¨ | Pic shopping |
| Janvier | Retour √† 5 | 1500‚Ç¨ | Automatic |

**Sans cloud :** Acheter 30 serveurs (300k‚Ç¨) pour 2 mois usage = b√™te.

**Avec cloud :** Payer 9000‚Ç¨ spot usage 2 mois = intelligent.

**Implication :** Pas de surprovisionnement, pas de sous-capacit√© ‚Üí rentabilit√© maximale.

### 2.5 Mesure de la Consommation (Pay-as-You-Go)

**D√©finition :** **Facturation √† l'usage** avec transparence totale sur ressources consomm√©es.

**Mod√®les de Facturation Courants :**

| Ressource | Unit√© de Facturation | Exemple Prix |
|-----------|---------------------|--------------|
| **Calcul (EC2)** | Par heure/seconde | 0,012‚Ç¨/h (~11‚Ç¨/mois 24h) |
| **Stockage (S3)** | Par GB/mois | 0,023‚Ç¨/GB (~23‚Ç¨/TB/mois) |
| **Transfert Out** | Par GB sortant | 0,09‚Ç¨/GB |
| **Bases de donn√©es** | Par heure + stockage | 0,025‚Ç¨/h + 0,1‚Ç¨/GB |
| **Serverless (Lambda)** | Par 1M invocations + dur√©e | 0,20‚Ç¨/M invocations + 0,0000166‚Ç¨/ms |

**Transparence Totale :**

```
Facture AWS Janvier 2026 :
‚îú‚îÄ EC2 : 2 instances √ó 0,012‚Ç¨/h √ó 730h = 17,52‚Ç¨
‚îú‚îÄ S3 : 500GB √ó 0,023‚Ç¨/GB = 11,50‚Ç¨
‚îú‚îÄ CloudFront (CDN) : 50GB √ó 0,085‚Ç¨/GB = 4,25‚Ç¨
‚îú‚îÄ RDS (Base donn√©es) : 0,025‚Ç¨/h √ó 730h = 18,25‚Ç¨
‚îú‚îÄ Lambda : 10M appels √ó 0,20‚Ç¨/M = 2,00‚Ç¨
‚îî‚îÄ **TOTAL : 53,52‚Ç¨/mois**

‚Üí Chaque service visible, co√ªts tra√ßables, responsabilit√© du client
```

**Avantage :** Vous ne payez que ce que vous consommez.

**Risque (Bill Shock) :** Si mal configur√©, une requ√™te infinie ‚Üí facture explosive.

**Exemple de Danger :**
```
Oubli : Laisser instance large (16 vCPU) overnight
Co√ªt : 0,85‚Ç¨/h √ó 8h = 6,80‚Ç¨ (benin)

Vrai danger : DDoS ou requ√™te boucle infinie
‚Üí 1000 requ√™tes/s √ó 100k appels Lambda overnight
‚Üí Co√ªt : 0,20‚Ç¨/M √ó 100M = 20,000‚Ç¨ FACTURE EN UNE NUIT

Mitigation : Alerte budget automatique
```

---

## CHAPITRE 3 : MOD√àLE DE RESPONSABILIT√â PARTAG√âE

### 3.1 Concept Fondamental

En cloud, la **s√©curit√© et conformit√© ne sont PLUS une responsabilit√© exclusive du client**. Elles sont **partag√©es entre client et fournisseur**, selon le mod√®le de service.

**Principe :** Plus le service monte l'√©chelle (IaaS ‚Üí PaaS ‚Üí SaaS), **moins le client contr√¥le**, mais **plus le fournisseur assume de responsabilit√©s**.

### 3.2 Responsabilit√©s par Mod√®le

#### **On-Premise (Datacenter Client)**

```
‚úã CLIENT RESPONSABLE (100%) :
‚îú‚îÄ S√©curit√© physique b√¢timent (cam√©ras, portes)
‚îú‚îÄ Mat√©riel serveurs, disques durs, r√©seau
‚îú‚îÄ Virtualisation (hyperviseur Xen/KVM)
‚îú‚îÄ Syst√®me d'exploitation (installation, patching)
‚îú‚îÄ Middleware, bases de donn√©es
‚îú‚îÄ Applications m√©tier
‚îú‚îÄ Donn√©es
‚îú‚îÄ Chiffrement, authentification
‚îú‚îÄ Sauvegardes, disaster recovery
‚îî‚îÄ Conformit√© l√©gale (RGPD, HDS, etc.)
```

**Implication :** Autonomie totale, MAIS responsabilit√© massive.

---

#### **IaaS ‚Äî Infrastructure as a Service**
*Exemples : AWS EC2, Azure VMs, Google Compute Engine*

```
Client responsable :
‚îú‚îÄ Syst√®me d'exploitation (patching s√©curit√©)
‚îú‚îÄ Applications m√©tier
‚îú‚îÄ Authentification utilisateurs
‚îî‚îÄ Donn√©es

Fournisseur responsable :
‚îú‚îÄ S√©curit√© physique datacenter
‚îú‚îÄ Mat√©riel serveurs
‚îú‚îÄ Hyperviseur (virtualisation)
‚îú‚îÄ R√©seau physique
‚îú‚îÄ Pare-feu core infrastructure
‚îî‚îÄ Redondance stockage
```

**Risque Majeur Client :** Mal configurer groupe de s√©curit√© AWS ‚Üí EC2 expos√©e Internet = 60% breaches cloud.

**Mitigation :** Infrastructure as Code (Terraform) + audits automatis√©s.

---

#### **PaaS ‚Äî Platform as a Service**
*Exemples : Google App Engine, AWS Elastic Beanstalk, Heroku, Cloud Run*

```
Client responsable :
‚îú‚îÄ Code application
‚îú‚îÄ Donn√©es m√©tier
‚îî‚îÄ Gestion authentification utilisateurs

Fournisseur responsable :
‚îú‚îÄ OS (et patches s√©curit√©)
‚îú‚îÄ Runtime (Java, Python, Node.js)
‚îú‚îÄ Middleware (serveurs app, cache)
‚îú‚îÄ Bases de donn√©es g√©r√©es
‚îú‚îÄ Scaling automatique
‚îî‚îÄ Infrastructure compl√®te
```

**Exemple Risque :** Injection SQL dans app ‚Üí database PaaS hack√©e.

**Implication :** Fournisseur g√®re infrastructure, client g√®re s√©curit√© applicative.

---

#### **SaaS ‚Äî Software as a Service**
*Exemples : Salesforce, Gmail, Microsoft 365, Slack*

```
Client responsable :
‚îú‚îÄ Donn√©es m√©tier
‚îú‚îÄ Configuration app (param√®tres)
‚îî‚îÄ Gestion des acc√®s utilisateurs

Fournisseur responsable :
‚îú‚îÄ Tout le reste (applications, serveurs, OS, sauvegardes, s√©curit√©)
‚îî‚îÄ Mises √† jour automatiques
```

**Implication :** Client = utilisateur, fournisseur = administrateur complet.

**Avantage :** Z√©ro maintenance technique.

**Inconv√©nient :** D√©pendance compl√®te, donn√©es = propri√©t√© fournisseur (TOS).

---

### 3.3 Implications de S√©curit√© Approfondies

#### **Risques Sp√©cifiques par Mod√®le**

| Mod√®le | Risque Majeur | Exemple | Mitigation |
|--------|-------------|---------|-----------|
| **IaaS** | Misconfiguration s√©curit√© | Groupe s√©curit√© permettant 0.0.0.0:22 | Audits automatis√©s (Prowler, etc.) |
| **PaaS** | Injection SQL, XSS | App non valid√©e entr√©es | OWASP Top 10 secure coding |
| **SaaS** | Compromission compte admin | Phishing mot de passe admin | MFA mandatory, SSO |
| **Tous** | Chiffrement donn√©es | Donn√©es en clair stockage | Chiffrement at-rest + TLS |

#### **Donn√©es en Transit vs At-Rest**

**Donn√©es en Transit :** Informations circulant r√©seau (client ‚Üí cloud).
- ‚úÖ Chiffrement TLS 1.3 (HTTPS) standard aujourd'hui
- ‚ö†Ô∏è Risque : Certificat auto-sign√©, connexion non encrypt√©e

**Donn√©es at-Rest :** Informations stock√©es disque.
- ‚úÖ Cloud fournisseur chiffre g√©n√©ralement (AES-256)
- ‚ö†Ô∏è Cl√©s g√©r√©es par fournisseur (vous n'avez pas le contr√¥le)
- ‚úÖ Option : Client-side encryption (vous d√©chiffrez localement)

**Exemple R√©el :** Slack chiffre donn√©es en transit (TLS), MAIS cl√©s de chiffrement **d√©tenus par Slack** (pas vous). Si Slack subpoenaed, donn√©es accessibles.

---

## CHAPITRE 4 : LES TROIS MOD√àLES DE D√âPLOIEMENT

### 4.1 Cloud Public

**D√©finition :** Infrastructure cloud **partag√©e entre plusieurs organisations clients**, exploit√©e par fournisseur tiers commercial.

#### **Caract√©ristiques**

| Aspect | Description |
|--------|-------------|
| **Propri√©taire** | Fournisseur tiers (AWS, Azure, GCP) |
| **Acc√®s** | Via Internet, ouvert monde entier |
| **Co√ªts** | Pay-as-you-go OPEX (pas CAPEX) |
| **Scalabilit√©** | Pratiquement illimit√©e |
| **S√©curit√©** | Responsabilit√© partag√©e |
| **Conformit√©** | D√©pend fournisseur (HDS, PCI-DSS) |
| **Contr√¥le** | Minimal sur infrastructure physique |

#### **Fournisseurs Majeurs (2024)**

```
R√©partition march√© IaaS+PaaS global :

AWS                32% - Leader incontest√©, services les plus nombreux
  ‚îú‚îÄ EC2 (VMs)
  ‚îú‚îÄ S3 (stockage)
  ‚îú‚îÄ RDS (bases de donn√©es)
  ‚îî‚îÄ Lambda (serverless)

Microsoft Azure    23% - Int√©gration forte Microsoft, forces enterprise
  ‚îú‚îÄ VMs
  ‚îú‚îÄ App Service (PaaS)
  ‚îú‚îÄ SQL Database
  ‚îî‚îÄ Synapse (analytics)

Google Cloud       11% - Forces en data, AI, machine learning
  ‚îú‚îÄ Compute Engine (VMs)
  ‚îú‚îÄ App Engine (PaaS)
  ‚îú‚îÄ BigQuery (analytics distribu√©)
  ‚îî‚îÄ Cloud AI Platform

Autres (Alibaba, IBM, Oracle, etc.) : 34%
```

#### **Analogie P√©dagogique : Pizza-as-a-Service**

Pour comprendre les mod√®les rapidement :

| Niveau | Analogie | Cloud | Responsabilit√©s Client |
|--------|----------|-------|----------------------|
| **On-Premise** | Cuisine maison | - | Acheter ingr√©dients, cuire, servir, nettoyer |
| **IaaS** | Take & Bake | EC2, GCE | Cuire pizza (acheter pr√©paration), servir, nettoyer |
| **PaaS** | Livraison pizza | App Engine | Servir, manger (fournisseur cuit) |
| **SaaS** | Restaurant | Gmail, Salesforce | Manger (restaurant g√®re tout) |

**D√©tail du mod√®le IaaS (Take & Bake) :**
```
Fournisseur cloud fourni :
‚îú‚îÄ Serveur physique (four)
‚îú‚îÄ Hyperviseur (cuisson automatis√©e)
‚îú‚îÄ R√©seau (livraison ingr√©dients)
‚îî‚îÄ Stockage disque (frigo)

Vous apportez :
‚îú‚îÄ Syst√®me d'exploitation (recette base)
‚îú‚îÄ Middleware, applications
‚îú‚îÄ Donn√©es m√©tier
‚îî‚îÄ S√©curit√© applicative
```

#### **Avantages ‚úÖ**

- ‚úÖ Co√ªts minimaux CAPEX (z√©ro investissement initial)
- ‚úÖ Scalabilit√© √† la demande sans limite technique
- ‚úÖ Services g√©r√©s (mises √† jour, patches, backups fournisseur)
- ‚úÖ Acc√®s global datacenters multiples (latence optimale)
- ‚úÖ Mod√®le pay-as-you-go = flexibilit√© financi√®re

#### **Inconv√©nients ‚ùå**

- ‚ùå **Vendor Lock-in** : APIs propri√©taires, migration co√ªteuse vers concurrent
- ‚ùå S√©curit√© partag√©e = responsabilit√© client importante (misconfiguration = breach)
- ‚ùå Performances variables (trafic r√©seau, partage ressources)
- ‚ùå Co√ªts impr√©dictibles si dimensionnement mauvais (runaway costs)
- ‚ùå Moins de contr√¥le configurations infrastructure

#### **Cas d'Usage Id√©aux**

- üéØ Startups, PME (budget IT limit√©)
- üéØ Applications web scalables (SaaS, APIs)
- üéØ D√©ploiement rapide prototypes (time-to-market critique)
- üéØ Services B2C distribu√©s (analytics, IoT)
- üéØ Devops first : √©quipes DevOps r√©duites

---

### 4.2 Cloud Priv√©

**D√©finition :** Infrastructure cloud **d√©di√©e √† une seule organisation**, soit h√©berg√©e **datacenter interne** soit **lou√© en exclusivit√©** aupr√®s fournisseur.

#### **Caract√©ristiques**

| Aspect | Description |
|--------|-------------|
| **Propri√©taire** | Organisation elle-m√™me ou lou√© exclusif |
| **Acc√®s** | R√©seau interne ou VPN s√©curis√© |
| **Co√ªts** | CAPEX (mat√©riel) + OPEX (√©quipes IT) |
| **Scalabilit√©** | Limit√©e par capacit√© physique existante |
| **S√©curit√©** | Contr√¥le complet |
| **Conformit√©** | Ma√Ætris√©e 100% par organisation |
| **Contr√¥le** | Total sur pile compl√®te |

#### **Solutions Cloud Priv√© Open-Source**

| Solution | Sp√©cialit√© | Exemple |
|----------|-----------|---------|
| **OpenStack** | Standard industrie complet | Hyperviseur Nova, r√©seau Neutron, stockage Cinder |
| **Proxmox** | PME, KVM natif, interface intuitive | Web UI, VM/conteneurs, clustering |
| **OpenNebula** | Orchestration l√©g√®re, multi-hyperviseur | Edge-friendly, portable |
| **CloudStack** | Enterprise-grade, AWS-like API | Mon√©tisation possible |

#### **Avantages ‚úÖ**

- ‚úÖ Contr√¥le s√©curit√© total (pas de partage ressources)
- ‚úÖ Conformit√© garantie (RGPD, HDS, donn√©es sensibles)
- ‚úÖ Performance pr√©visible (pas de contention)
- ‚úÖ Z√©ro vendor lock-in (open-source)
- ‚úÖ Amortissement long terme (5+ ans = ROI positif)

#### **Inconv√©nients ‚ùå**

- ‚ùå Co√ªts CAPEX √©normes (serveurs : 50-100k‚Ç¨+)
- ‚ùå Scalabilit√© limit√©e par infrastructure physique
- ‚ùå √âquipes IT internes requises (expertise √©lev√©e)
- ‚ùå Maintenance logicielle = responsabilit√© client
- ‚ùå ROI long terme (3-5 ans minimum avant profitabilit√©)

#### **Cas d'Usage Id√©aux**

- üéØ Donn√©es critiques, sensibles (sant√©, finance, gouvernement)
- üéØ Conformit√© l√©gale stricte (RGPD, HDS, cloud souverain)
- üéØ Applications latence z√©ro (trading temps r√©el)
- üéØ Grands groupes √©quipes IT existantes
- üéØ Industries r√©glement√©es (√©nergie, d√©fense, finance)

---

### 4.3 Cloud Hybride

**D√©finition :** **Combinaison cloud public + cloud priv√©** avec int√©gration seamless, partageant donn√©es et applications.

#### **Caract√©ristiques**

| Aspect | Description |
|--------|-------------|
| **Propri√©taire** | Mixte (organisation + fournisseur public) |
| **Acc√®s** | R√©seau priv√© + Internet selon besoin |
| **Co√ªts** | CAPEX hybride + OPEX hybride |
| **Scalabilit√©** | √âlastique (d√©bordement public quand besoin) |
| **S√©curit√©** | Strat√©gies mixtes par type charge |
| **Conformit√©** | Donn√©es sensibles priv√©, autres public |
| **Contr√¥le** | Granulaire par ressource |

#### **Architectures Hybrides Courantes**

##### **1. Cloud Burst (D√©bordement Dynamique)**

```
Architecture :

Priv√© (On-Premise) : Infrastructure de base stable
‚îú‚îÄ 5 serveurs permanents
‚îú‚îÄ Capacit√© fixe = co√ªts fixes pr√©visibles
‚îî‚îÄ Co√ªt : 500k‚Ç¨ CAPEX + 50k‚Ç¨/an OPEX

Public (AWS) : Ressources √©lastiques
‚îú‚îÄ 0 instances en charge normal
‚îú‚îÄ N instances quand pics
‚îî‚îÄ Co√ªt : Variable selon demande

Cas d'Usage : E-commerce pics saisonniers
‚îú‚îÄ Janvier-Octobre : 5 serveurs priv√© (500‚Ç¨/mois)
‚îú‚îÄ Novembre-D√©cembre : +30 instances public (peak 9k‚Ç¨/mois)
‚îú‚îÄ Janvier : Retour 5 serveurs privat√©
‚îî‚îÄ Total ann√©e : 6√ó500 + 2√ó9k + 4√ó500 = 25k‚Ç¨
```

**Avantage :** Donn√©es sensibles (client info) restent priv√©, scaling √©conome.

---

##### **2. Cloud Tiering (Stratification par Temp√©rature Donn√©es)**

```
Donn√©es "Chaudes" (acc√®s fr√©quent) :
‚îú‚îÄ Base de donn√©es active (transactions)
‚îú‚îÄ Cache applicatif
‚îî‚îÄ Localisation : Cloud public (fast, AWS RDS)

Donn√©es "Ti√®des" (acc√®s occasionnel) :
‚îú‚îÄ Donn√©es 6-12 mois anciennes
‚îî‚îÄ Localisation : Cloud priv√© (co√ªts r√©duits)

Donn√©es "Froides" (archives) :
‚îú‚îÄ L√©gales, compliance requises
‚îú‚îÄ Acc√®s rare
‚îî‚îÄ Localisation : Stockage priv√© bon march√© (Glacier, Nearline)
```

**B√©n√©fice :** Optimisation co√ªts ‚Äî vous payez complexit√© selon temp√©rature donn√©es.

---

#### **Avantages ‚úÖ**

- ‚úÖ Flexibilit√© optimale (co√ªts, s√©curit√©, scalabilit√©)
- ‚úÖ Scalabilit√© √† demande sans CAPEX √©normes
- ‚úÖ Donn√©es sensibles localis√©es, autres scalables
- ‚úÖ Continuit√© service et failover rapide
- ‚úÖ Mitigation vendor lock-in (diversification)

#### **Inconv√©nients ‚ùå**

- ‚ùå Complexit√© accrue (2 infrastructures diff√©rentes)
- ‚ùå Co√ªts int√©gration √©lev√©s (middleware, outils)
- ‚ùå Comp√©tences multiples requises
- ‚ùå Latence inter-cloud possible (donn√©es passent Internet)
- ‚ùå Conformit√© fragment√©e (audit complexe)

#### **Cas d'Usage Id√©aux**

- üéØ Entreprises en migration progressive vers cloud
- üéØ Applications legacy + modernes coexistent
- üéØ Conformit√© partielle (donn√©es sensibles on-site, services public)
- üéØ Haute disponibilit√© requise
- üéØ Optimisation co√ªts (public variable + priv√© fixe)

---

### 4.4 Tableau Comparatif Synth√©tique

| Crit√®re | **Cloud Public** | **Cloud Priv√©** | **Hybride** |
|---------|---|---|---|
| **Co√ªts CAPEX** | 0‚Ç¨ | 500k‚Ç¨+ | 300k‚Ç¨+ |
| **Co√ªts OPEX/mois** | 100-1k‚Ç¨ | 10k‚Ç¨ | 5k‚Ç¨ |
| **Scalabilit√©** | Illimit√©e ‚úÖ | Limit√©e ‚ö†Ô∏è | √âlastique ‚úÖ |
| **S√©curit√©** | Partag√©e ‚ö†Ô∏è | Totale ‚úÖ | Granulaire ‚úÖ |
| **Conformit√©** | Fournisseur-d√©pendant | Totale ‚úÖ | Configurable |
| **Vendor Lock-in** | Risque majeur ‚ùå | Z√©ro ‚úÖ | Mitig√© ‚úÖ |
| **Time-to-Deploy** | 5 min | 2-3 mois | 2 semaines |
| **Expertise requise** | Moyenne | √âlev√©e | Tr√®s √©lev√©e |

---

## CHAPITRE 5 : CLASSIFICATION DES SERVICES CLOUD

### 5.1 IaaS ‚Äî Infrastructure as a Service

**D√©finition :** Client loue **infrastructure informatique virtualis√©e** (serveurs, stockage, r√©seau). Client g√®re OS et applications.

**Services Principaux :**
- Machines virtuelles (AWS EC2, Azure VMs, Google Compute Engine)
- Stockage objet (AWS S3, Azure Blob Storage)
- Bases de donn√©es (g√©r√©es) (AWS RDS, Azure SQL Database)
- R√©seaux virtuels (VPCs, Security Groups)

**Responsabilit√©s :**
- ‚úã Client : OS, patchs s√©curit√©, applications, donn√©es
- üõ°Ô∏è Fournisseur : Infrastructure, hyperviseur, r√©seau physique

**Cas d'Usage :** Applications web traditionnelles, serveurs web/appli, bases de donn√©es.

**Co√ªt Exemple :** 0,012‚Ç¨/h instance t2.micro AWS (~11‚Ç¨/mois 24h).

---

### 5.2 PaaS ‚Äî Platform as a Service

**D√©finition :** Fournisseur g√®re **infrastructure + OS + runtime**. Client d√©ploie **code applicatif seulement**.

**Services Principaux :**
- Google App Engine (deploy automatique)
- AWS Elastic Beanstalk (PaaS sur EC2)
- Heroku (code ‚Üí production, push git)
- Google Cloud Run (containers serverless)

**Responsabilit√©s :**
- ‚úã Client : Code, donn√©es, configuration
- üõ°Ô∏è Fournisseur : OS, runtime, scaling, d√©ploiement, backups

**Avantages :**
- ‚úÖ Zero ops (fournisseur g√®re infrastructure)
- ‚úÖ D√©ploiement trivial (push code)
- ‚úÖ Scaling automatique int√©gr√©
- ‚úÖ Services g√©r√©s inclus (databases, caching)

**Inconv√©nients :**
- ‚ùå Moins de contr√¥le (customization limit√©e)
- ‚ùå Vendor lock-in (APIs propri√©taires)
- ‚ùå Co√ªts moins pr√©dictibles (scaling automatique)

**Cas d'Usage :** Startups web, APIs rapides, prototypes.

**Co√ªt Exemple :** Cloud Run: 0,20‚Ç¨ par million invocations + 0,0000166‚Ç¨ par ms ex√©cution.

---

### 5.3 SaaS ‚Äî Software as a Service

**D√©finition :** Fournisseur g√®re **application compl√®te**. Client = utilisateur uniquement.

**Services Courants :**
- Email (Gmail, Outlook)
- Collaboration (Google Workspace, Microsoft 365)
- CRM (Salesforce)
- Productivit√© (Slack, Figma, Notion)
- Analytics (Mixpanel, Amplitude)

**Responsabilit√©s :**
- ‚úã Client : Donn√©es m√©tier, configuration, gestion acc√®s utilisateurs
- üõ°Ô∏è Fournisseur : Tout (application, serveurs, s√©curit√©, mises √† jour)

**Avantages :**
- ‚úÖ Z√©ro maintenance technique
- ‚úÖ Mises √† jour automatiques
- ‚úÖ Accessibilit√© universelle (navigateur)
- ‚úÖ Co√ªts pr√©dictibles (abonnement fixe)

**Inconv√©nients :**
- ‚ùå D√©pendance compl√®te fournisseur
- ‚ùå Donn√©es = propri√©t√© fournisseur (TOS)
- ‚ùå Customization tr√®s limit√©e
- ‚ùå Lock-in maximum

**Cas d'Usage :** Outils productivit√©, CRM, communication.

**Co√ªt Exemple :** Salesforce 100‚Ç¨/utilisateur/mois.

---

### 5.4 FaaS ‚Äî Functions-as-a-Service (Serverless)

**D√©finition :** Mod√®le o√π client d√©ploie **fonctions √©v√©nementielles isol√©es** sans g√©rer serveurs. Scaling automatique, paiement milliseconde.

**Services :**
- AWS Lambda
- Google Cloud Functions
- Azure Functions
- IBM Cloud Functions

**Responsabilit√©s :**
- ‚úã Client : Code fonction seulement
- üõ°Ô∏è Fournisseur : Tout (serveurs, OS, scaling, infrastructure)

**Cas d'Usage Optimaux :**
- Webhooks (GitHub push ‚Üí slack notification)
- Traitement asynchrone (upload image ‚Üí redimensionnement)
- APIs REST l√©g√®res et stateless
- Batch jobs √©v√©nementiels

**Avantages :**
- ‚úÖ Co√ªts minimaux (paiement milliseconde)
- ‚úÖ Scaling instantan√© (0 ‚Üí 1000 invocations/s)
- ‚úÖ Z√©ro infrastructure management
- ‚úÖ D√©ploiement trivial (upload code)

**Inconv√©nients :**
- ‚ùå Cold start (1-5 sec initialisation premi√®re invocation)
- ‚ùå Vendor lock-in extr√™me (APIs propri√©taires)
- ‚ùå Limitations (timeout 15 min, m√©moire max 10GB)
- ‚ùå D√©buggage complexe (logs cloud-only)
- ‚ùå Co√ªts explosifs si trafic impr√©visible

**Co√ªt Exemple :** AWS Lambda 0,20‚Ç¨/million invocations + 0,0000166‚Ç¨/ms.

**Exemple R√©el (Webhook GitHub) :**
```
√âv√©nement : Commit push √† repository

Fonction Lambda (Node.js) :
  ‚îú‚îÄ Re√ßoit webhook GitHub
  ‚îú‚îÄ Appelle Slack API ‚Üí post message
  ‚îú‚îÄ Retourne HTTP 200
  ‚îî‚îÄ Ex√©cution 50ms

Co√ªts mensuels :
  ‚îú‚îÄ 1000 commits/mois = 1000 invocations
  ‚îú‚îÄ Co√ªt invocations : 1000 / 1M √ó 0,20‚Ç¨ = 0,0002‚Ç¨
  ‚îú‚îÄ Co√ªt ex√©cution : 1000 √ó 50ms √ó 0,0000166‚Ç¨ = 0,0008‚Ç¨
  ‚îî‚îÄ TOTAL : 0,001‚Ç¨ (~n√©gligeable)
```

---

## CHAPITRE 6 : TENDANCES 2024-2026

### 6.1 Edge Computing

**D√©finition :** Traitement des donn√©es **√† la p√©riph√©rie du r√©seau** plut√¥t qu'en datacenter distant, r√©duisant latence et bande passante.

**Exemples Edge Computing :**

| Cas d'Usage | Latence Cloud | Latence Edge | Implication |
|------------|--------------|------------|-------------|
| Voiture autonome (freinage) | 100-500ms | 5-10ms | **Impossible cloud** |
| Cam√©ra surveillance + IA | 200-500ms | 10-50ms | Cloud = trop lent |
| Jeu multijoueur FPS | 50-100ms | 10-20ms | Cloud = unplayable |
| IoT capteurs industrie | 500ms+ | 10-50ms | OK cloud mais edge meilleur |

**Tendances 2024-2026 :**
1. **5G + Edge** : Op√©rateurs t√©l√©com d√©ploient edge aux antennes 5G
2. **Kubernetes Edge** : K3s, MicroK8s (Kubernetes l√©ger < 100MB)
3. **TinyML** : Mod√®les IA compress√©s pour ex√©cution locale
4. **Zero Trust Security** : Authentification distribu√©e + chiffrement local

**Implication :** Cloud computing de demain = cloud central + edge distribu√©.

---

### 6.2 FinOps (Financial Operations)

**D√©finition :** Pratique o√π **ing√©nieurs prennent responsabilit√© co√ªts** de leurs architectures cloud.

**Probl√®me :** √âlasticit√© cloud cr√©e **risque financier √©norme**.

**Exemple de "Bill Shock" :**
```
Oubli : Laisser instance large (16 vCPU) activ√©e Friday 18h
Retour lundi 9h = 63 heures oubli√©es
Co√ªt : 0,85‚Ç¨/h √ó 63h = 53‚Ç¨ (pas dramatique)

MAIS : Vrai danger
DDoS attaque ou requ√™te boucle infinie
‚Üí 1000 requ√™tes/s Lambda √ó 72h = 259 Milliards invocations
‚Üí 259M √ó 0,20‚Ç¨/M = 51,800‚Ç¨ FACTURE UNE NUIT

Mitigation : Alerte budget CloudFormation
```

**Pratiques FinOps :**
- Tagging ressources (projet, √©quipe, environnement)
- Alertes budget (arr√™ter si >X‚Ç¨/jour)
- Reserved instances (50% r√©duction annuel si pr√©vu)
- Spot instances (70% r√©duc si flexible timing)
- Right-sizing (utiliser type instance juste assez)

**Enjeu Culture :** Ing√©nieur responsable co√ªts = ing√©nieur mature.

---

### 6.3 Souverainet√© Num√©rique

**Contexte :** Tensions g√©opolitiques + RGPD ‚Üí donn√©es **doit r√©sider juridiction sp√©cifique**.

**D√©finition :** Cloud souverain = donn√©es restent sous **contr√¥le l√©gal √âtat/r√©gion**.

**Probl√®me R√©solu :**
- ‚ùå Avant : Donn√©es EU stock√©es AWS USA ‚Üí CLOUD Act am√©ricain s'applique
- ‚úÖ Maintenant : Cloud EU (France, Allemagne) ‚Üí RGPD s'applique

**Fournisseurs Cloud Souverain :**
- **France** : OVH, Scaleway, Outscale (ex-Inovalis)
- **Allemagne** : Deutsche Telekom T-Systems
- **Europe** : Gaia-X initiative (f√©d√©ration clouds europ√©ens)

**Conformit√© SecNumCloud (France) :**
- Donn√©es sensibles (sant√©, gouvernement) doivent √™tre h√©berg√©es infrastructure approuv√©e
- Exemple : H√¥pital fran√ßais doit utiliser cloud HDS certifi√©

**Implication :** 2026, souverainet√© = exigence contractuelle, pas optionnel.

---

### 6.4 Cloud Native et 12-Factor App

**Concept :** Applications **architectur√©es pour le cloud**, pas simplement "migr√© vers cloud".

**12-Factor App (Heroku methodology) :**

| Factor | Concept | Exemple |
|--------|---------|---------|
| **1. Codebase** | Un repository git = plusieurs d√©ploiements | M√™me code, configs diff√©rentes per env |
| **2. Dependencies** | D√©clarer explicitement d√©pendances | package.json, requirements.txt, Gemfile |
| **3. Config** | Stocker configuration en environnement | process.env.DB_URL, pas hardcod√© |
| **4. Backing Services** | Traiter BD/cache comme ressources attachables | Changer DB dev ‚Üî prod = changement config |
| **5. Build/Run** | Strict s√©paration build et run | Docker : build une fois, run anywhere |
| **6. Processes** | Stateless processes | Pas fichier session disque local |
| **7. Port Binding** | Service exporte port HTTP | App listen port 8080, pas hardcoded |
| **8. Concurrency** | Process model horizontal scaling | 10 instances identiques, pas 1 monstre |
| **9. Disposability** | Fast startup/graceful shutdown | App d√©marre <5s, arr√™t propre (10s timeout) |
| **10. Dev/Prod Parity** | Environnements identiques | Docker = m√™me image dev et prod |
| **11. Logs** | Logs ‚Üí stdout, pas fichiers | App envoie stdout, fournisseur r√©colte |
| **12. Admin Tasks** | Admin tasks = one-off process | Migrations DB = conteneur s√©par√©, pas manual SSH |

**Implication :** Bien architectur√© = application survit dans une r√©alit√© cloud (instances √©ph√©m√®res).

---

## CHAPITRE 7 : MATRICE DE S√âLECTION D√âCISIONNELLE

### 7.1 Les 6 Crit√®res Majeurs

#### **1. Sensibilit√© des Donn√©es**

| Niveau | Type Donn√©es | Cloud Recommand√© |
|--------|------------|------------------|
| **CRITIQUE** | Donn√©es sant√©, juridiques, gouvernement | Cloud priv√© ou EU souverain |
| **SENSIBLE** | Donn√©es client, transactions financi√®res | Hybride (donn√©es priv√©, services public) |
| **PUBLIC** | Analytics, contenus marketing | Cloud public (AWS, Azure, GCP) |

---

#### **2. Budget Disponible**

| Budget | Horizon | Recommandation |
|--------|---------|-----------------|
| < 100k‚Ç¨ | Startup | Cloud public (AWS Free tier, GCP Always Free) |
| 100k - 500k‚Ç¨ | PME | Cloud public ou hybrid burst |
| 500k - 2M‚Ç¨ | ETI | Cloud hybride (base priv√© + burst public) |
| > 2M‚Ç¨ | Groupe | Cloud priv√© souverain + hybrid public |

---

#### **3. Volume de Donn√©es**

| Volume | Nature | Recommandation |
|--------|--------|-----------------|
| < 1TB | Petit projet | Cloud public (co√ªts n√©gligeables) |
| 1-10TB | Applicatif normal | Cloud public ou priv√© (co√ªts mod√©r√©s) |
| 10-100TB | BigData light | Hybride (donn√©es froides priv√©, chaudes public) |
| > 100TB | BigData heavy | Cloud priv√© (bande passante inter-cloud tr√®s co√ªteuse) |

**Important :** Transfert donn√©es cloud public = 0,09‚Ç¨/GB sortant. Transf√©rer 1TB = 90‚Ç¨.

---

#### **4. Conformit√©/R√©glementation**

| Secteur | Exigences | Solution |
|---------|-----------|----------|
| **Finance** | PCI-DSS, B√¢le III, MiFID | Cloud priv√© s√©curis√© ou AWS/Azure certifi√© |
| **Sant√©** | HDS, RGPD, HIPAA | Cloud priv√© ou cloud public certifi√© HDS |
| **Public** | RGPD, Cloud Act | Cloud EU souverain obligatoire |
| **Pas r√®gles** | Donn√©es publiques | Cloud public flexible |

---

#### **5. Latence Tol√©rable**

| Application | Latence Cible | Recommandation |
|------------|-------------|-----------------|
| Web statique | < 1000ms | Cloud public multiregion |
| APIs REST | < 100ms | Cloud public region proche |
| Temps r√©el (chat) | < 50ms | Cloud public + edge processing |
| Voiture autonome | < 10ms | Edge local obligatoire |
| Trading HFT | < 5ms | Datacenter priv√© on-site |

---

#### **6. Comp√©tences IT Disponibles**

| Comp√©tences | √âquipe | Recommandation |
|------------|--------|-----------------|
| **Aucun DevOps** | 0 ing√©nieur cloud | SaaS uniquement (Salesforce, Microsoft 365) |
| **D√©butants** | 1-2 DevOps juniors | Cloud public + PaaS (gestion fournisseur) |
| **Exp√©riment√©s** | 3-5 DevOps seniors | Cloud public IaaS + orchestration custom |
| **Experts** | 5+ team members | Cloud priv√© + hybrid (besoin IT interne √©lev√©) |

---

### 7.2 Matrice D√©cisionnelle Compl√®te

Pour choisir, cotez votre situation sur 6 crit√®res, puis consultez la matrice :

```
Cotation : 1 (tr√®s faible) √† 5 (tr√®s √©lev√©)

‚ñ° Sensibilit√© donn√©es (1-5) : ___
‚ñ° Budget (1-5) : ___
‚ñ° Volume donn√©es (1-5) : ___
‚ñ° Exigence conformit√© (1-5) : ___
‚ñ° Latence critique (1-5) : ___
‚ñ° Comp√©tences IT (1-5) : ___
```

**D√©cision :**

| Profil | Score Sensibilit√©+Conformit√© | Score Budget+Comp√©tences | Recommandation |
|--------|---------------------------|----------------------|-----------------|
| Startup, donn√©es publiques | 1-3 | 5 (budget faible, DevOps expert) | **AWS Public** |
| PME classique | 3 | 3-4 | **Cloud Hybride Burst** |
| Banque, donn√©es critiques | 5 | 5 (budget ‚àû, √©quipe IT) | **Cloud Priv√© + Public EU** |
| Gouvernement | 5 | 4 | **Cloud Souverain EU** |
| Scale-up croissance rapide | 2-3 | 3 | **AWS/Azure Public** |

---

## CONCLUSION

Le cloud computing transforme infrastructure IT moderne, mais **aucune solution universelle** n'existe. Succ√®s d√©pend :

1. ‚úÖ **Comprendre les 5 caract√©ristiques NIST** = fondations solides
2. ‚úÖ **Clarifier mod√®le d√©ploiement** (public/priv√©/hybride)
3. ‚úÖ **S√©lectionner services** (IaaS/PaaS/SaaS/FaaS)
4. ‚úÖ **√âvaluer matrice d√©cisionnelle** = choix justifi√©
5. ‚úÖ **Adopter culture FinOps** = ma√Ætriser co√ªts

**Prochain chapitre (Module 2) :** Approfondir AWS, Azure, GCP et cas d'usage sp√©cialis√©s.

**Prochain TP :** D√©ployer application sur Cloud Run (PaaS serverless) = mettre en pratique concepts.

---

## GLOSSAIRE

**CAPEX :** D√©penses d'investissement (capital expenditure) ‚Äî achat mat√©riel long terme.

**OPEX :** D√©penses de fonctionnement (operational expenditure) ‚Äî co√ªts courants, factures mensuelles.

**Hyperviseur :** Logiciel virtualisation (Xen, KVM, Hyper-V) = g√®re machines virtuelles.

**Vendor Lock-in :** D√©pendance fournisseur, migration difficile vers concurrent.

**RTO (Recovery Time Objective) :** Temps max acceptable arr√™t service apr√®s panne.

**RPO (Recovery Point Objective) :** Volume donn√©es max acceptable perdre apr√®s panne.

**Multi-tenancy :** Partage ressources plusieurs clients (s√©curit√© par isolation, pas s√©paration physique).

**Serverless :** Fournisseur g√®re serveurs invisiblement, client paie invocations.

**Stateless :** Application sans √©tat = red√©marrage n'impacte pas fonctionnement (pas donn√©es session disque).

**TLS :** Transport Layer Security ‚Äî chiffrement r√©seau (HTTPS).

---


# MODULE 2 : PANORAMA DES SOLUTIONS CLOUD

## Support de Cours √âtudiant ‚Äì Licence 3 BUT R&T
**Date :** Janvier 2026  

---

## INTRODUCTION : LA GUERRE DES CLOUDS (2026)

En 2026, le march√© cloud atteint **750 milliards ‚Ç¨** de revenus globaux. Les trois g√©ants (AWS, Azure, GCP) contr√¥lent **63%** du march√©, mais **aucun ne domine 100%**. Pourquoi ? Parce que chaque fournisseur excelle dans des domaines diff√©rents :
- **AWS** : G√©n√©raliste, 30% march√©, complexit√©/maturit√©
- **Azure** : Int√©gration Microsoft, 20% march√©, Fortune 500
- **GCP** : IA g√©n√©rative 2025, 13% march√©, data/ML leaders

Parall√®lement, une **r√©volution souveraine** √©merge en Europe : les donn√©es critiques exigent des garanties l√©gales (SecNumCloud, RGPD, Cloud Act). Les acteurs locaux (OVHcloud, Scaleway, Bleu, S3NS) offrent une alternative aux Big Three am√©ricains.

**Objectif du Module 2** : Justifier le choix d'une plateforme cloud pour une organisation r√©elle en comparant forces/faiblesses, co√ªts et impacts r√©glementaires.

---

## CHAPITRE 1 : LES "HYPERSCALERS" (PUBLIC CLOUD)

### 1.1 Amazon Web Services (AWS) ‚Äì Le Pionnier

#### **Historique & Positionnement**
- **Cr√©√©** : 2006 (premi√®re plateforme cloud commerciale)
- **Leader** : 30% march√© global (Q2 2025, Synergy Research)
- **Sp√©cialit√©** : G√©n√©raliste, "+200 services", standard de facto

#### **Forces Principales**
1. **Maturit√© & Ecosyst√®me** : 20 ans d'it√©ration, √©cosyst√®me partenaire massif
2. **Catalogue incomparable** : EC2, S3, Lambda, RDS, DynamoDB, SageMaker, etc.
3. **R√©gions g√©ographiques** : 33 r√©gions, 105 zones de disponibilit√© (couverture mondiale)
4. **March√© de talents** : Plus grande demande d'expertise AWS sur le march√©

#### **Faiblesses**
1. **Courbe d'apprentissage** : Interface complexe, centaines de services cr√©e confusion
2. **Facturation opaque** : "AWS Pricing Calculus" n√©cessaire pour √©viter factures surprises
3. **Risque vendor lock-in** : Services propri√©taires (DynamoDB, SageMaker) difficiles √† migrer

#### **Services Phares**

| Service | Type | Use Case |
|---------|------|----------|
| **EC2** | Compute | VMs on-demand, auto-scaling |
| **S3** | Stockage | Object storage, backups, CDN |
| **Lambda** | Serverless | Fonctions sans serveur, automatisation |
| **RDS** | Database | Managed SQL (PostgreSQL, MySQL) |
| **DynamoDB** | Database | NoSQL scalable, latency < 1ms |
| **SageMaker** | ML | Notebooks, training, deployment ML |

#### **Mod√®le Tarifaire 2025**

**AWS Free Tier (R√©volution Juillet 15, 2025)**
```
AVANT (Pr√©-juillet 2025)  : 12 mois gratuits + services √† limits
APR√àS (Post-juillet 2025) : 
  ‚Ä¢ FREE PLAN      : $100 cr√©dits + $100 onboarding = $200 total
  ‚Ä¢ Dur√©e          : 6 mois OU jusqu'√©puisement cr√©dits
  ‚Ä¢ Aucun risque   : Pas de carte bancaire requise au-del√† des $200
```

**Impact p√©dagogique** : √âtudiants DOIVENT choisir FREE PLAN au signup (z√©ro risque facturation). Budget d'environ **$200 = ~100h de t2.micro**.

**Tarification √† la demande (Pay-as-you-go)**
- t2.micro : $0.0116/h (~‚Ç¨8.50/mois)
- m5.large : $0.096/h (~‚Ç¨70/mois)
- c5.2xlarge : $0.34/h (~‚Ç¨250/mois)
- Stockage S3 : $0.023/Go/mois

---

### 1.2 Microsoft Azure ‚Äì L'Int√©grateur

#### **Historique & Positionnement**
- **Cr√©√©** : 2010 (apr√®s AWS, rattrapage progressif)
- **Leader** : 20% march√© global (Q2 2025)
- **Force** : Int√©gration √©cosyst√®me Microsoft, hybrid cloud

#### **Forces Principales**
1. **Int√©gration Microsoft** : Office 365, Active Directory, Copilot, Dynamics natifs
2. **Hybrid Cloud Leader** : **Azure Arc** permet g√©rer ressources on-prem et multi-cloud
3. **March√© Entreprise** : 85% Fortune 500 utilisent Azure
4. **OpenAI First** : Acc√®s prioritaire OpenAI/Copilot

#### **Faiblesses**
1. **Portal complexe** : Interface parfois lente, n√©cessite app√©tit technologie
2. **Licensing labyrinthique** : "Software Assurance" confus pour PME
3. **Moins de services sp√©cialis√©s** : Galaxie d'options, moins intuitif qu'AWS

#### **Services Phares**

| Service | Type | √âquivalent AWS |
|---------|------|-----------------|
| **Virtual Machines** | Compute | EC2 |
| **App Services** | PaaS | Elastic Beanstalk |
| **Azure SQL Database** | Database Managed | RDS (SQL) |
| **Cosmos DB** | NoSQL Global | DynamoDB |
| **Azure Arc** | Hybrid Cloud | N/A (diff√©renciant) |
| **Copilot Enterprise** | AI/Productivity | SageMaker |

#### **Concept Cl√© : Resource Groups & Azure Arc**

**Resource Groups** = conteneurs logiques regroupant ressources d'un projet.
```
Exemple :
  Resource Group "E-Commerce-Prod"
    - Virtual Network (VNet)
    - App Services (3 instances)
    - SQL Database
    - Storage Account
  ‚Üí Permet facturation/permissions par projet
```

**Azure Arc** = gestion centralis√©e pour ressources partout (cloud + on-prem).
```
Cas d'usage :
  - Serveur on-prem manag√© via Azure portal
  - Policies applicables uniform√©ment
  - Cost tracking global
  ‚Üí Unique point Azure vs AWS (pas d'√©quivalent direct)
```

---

### 1.3 Google Cloud Platform (GCP) ‚Äì Le Sp√©cialiste IA/Data

#### **Historique & Positionnement**
- **Cr√©√©** : 2008 (interne avant commercial)
- **Leader** : 13% march√© global (Q3 2025, croissance +25% YoY)
- **Sp√©cialit√©** : Data Analytics, Machine Learning, IA g√©n√©rative

#### **Forces Principales**
1. **R√©seau backbone Google** : Latence ultra-faible (11 ms global vs 50+ concurrents)
2. **Kubernetes natif (GKE)** : Cr√©√© par Google, support enterprise premium
3. **IA g√©n√©rative leader 2025** : Vertex AI + stack complet (Gemini, Veo, Imagen, Lyria)
4. **BigQuery dominant** : Data warehouse + analytics $6.25/To (vs redshift $5)

#### **Faiblesses**
1. **Portfolio fragment√©** : Produits lanc√©s/abandonn√©s r√©guli√®rement (ex: Fabric, Cloud SQL)
2. **Moins de services "legacy"** : Startup-oriented, moins COBOL/SAP
3. **Interface ergonomie** : Console pas aussi intuitive qu'AWS

#### **Services Phares**

| Service | Type | Force |
|---------|------|-------|
| **Compute Engine** | VM | Performance r√©seau |
| **GKE** | Kubernetes | Support natif, auto-scaling |
| **BigQuery** | Data Warehouse | Requ√™tes <1s sur p√©tabytes |
| **Vertex AI** | ML/LLM | Leader IA g√©n√©rative |
| **Cloud Functions** | Serverless | Go/Python optimis√© latence |
| **Firestore** | NoSQL | Real-time, multi-region |

#### **GCP Vertex AI & IA G√©n√©rative Stack (2025)**

**Gemini 2.5 Flash**
- Mod√®le par d√©faut, multi-modal (texte, image, audio, video)
- Latency <100ms, contexte 1M tokens
- R√©duction co√ªts : 2x moins cher que GPT-4o

**Generative Capabilities Compl√®tes**
```
Texte    ‚Üí Gemini 2.5 Flash / Pro (LLM g√©n√©raliste)
Image    ‚Üí Imagen 3 (text-to-image haute qualit√©)
Video    ‚Üí Veo 2 (video generation/editing)
Audio    ‚Üí Chirp 3 (speech synthesis + custom voice)
Musique  ‚Üí Lyria (text-to-music, NOUVEAU 2025)
S√©curit√© ‚Üí SynthID (watermarking anti-deepfakes)
```

**Tarification Vertex AI (2025)**
- Gemini 2.5 Flash : $0.075/M input tokens, $0.30/M output tokens
- Imagen 3 : $0.025/image
- Veo 2 : $0.06/second video
- BigQuery : $6.25/To analysed

---

## CHAPITRE 2 : L'ALTERNATIVE SOUVERAINE & EUROP√âENNE

### 2.1 Le Probl√®me : Cloud Act & Souverainet√© des Donn√©es

**Cloud Act (2018, USA)** : Les autorit√©s am√©ricaines peuvent acc√©der √† TOUTE donn√©e stock√©e sur serveurs US, peu importe la juridiction du client. L√©galement, votre "secret bancaire" fran√ßais peut √™tre l√ª par le FBI.

**Cons√©quences pour l'Europe** :
- Organisations critiques (banques, sant√©, d√©fense) : interdites AWS/Azure/GCP
- Donn√©es personnelles : RGPD impose "d√©terminisme juridique" (donn√©es UE = loi UE)
- Entreprises strat√©giques : gouvernements encouragent "cloud souverain"

### 2.2 Les Champions Europ√©ens

#### **OVHcloud ‚Äì Le G√©ant Fran√ßais**

**Profil**
- Cr√©√© : 1999, headquartered Roubaix, France
- March√© : 4% cloud public Europe, leader France
- USP : Performance/prix Bare Metal, donn√©es 100% UE

**Forces**
- Pricing ultra-comp√©titif : Bare Metal 32 CPU/256GB RAM = ‚Ç¨350/mois (vs AWS ‚Ç¨2000+)
- Infrastructures France/Allemagne/Pologne : Aucune donn√©e US
- Support fran√ßais : Pas de "attendre Slack"
- Offre souveraine certifi√©e SecNumCloud

**Faiblesses**
- Catalogue services : <100 services (vs AWS 200+)
- Talent pool : Moins d'expertise France (vs AWS international)
- Support : 24/7 bon, pas "white glove" Fortune 500

#### **Scaleway ‚Äì Le Challenger Moderne**

**Profil**
- Cr√©√© : 2010, Paris
- Marque : Developer-friendly, pricing transparent
- Sp√©cialit√© : ARM instances √©co-responsables, DevOps tools

**Forces**
- UX/Documentation : Exceptionnelle pour startups
- Eco-instances ARM64 : 70% moins cher que x86, -30% CO2
- Transparent pricing : Aucune "surprise" facturation
- Datacenter Europe : Strasbourg, Paris, Amsterdam

**Faiblesses**
- Services moins complets : <80 services
- Pas de hybrid cloud tool (vs Azure Arc)
- Scaling global : Moins de r√©gions (5 vs 33 AWS)

---

### 2.3 Le "Cloud de Confiance" (SecNumCloud 3.2)

**SecNumCloud** = Label ANSSI (Agence Nationale de la S√©curit√© Informatique) d√©livr√© aux fournisseurs offrant :
- Donn√©es h√©berg√©es UE (RGPD)
- Encryption "known plaintext impossible" (cl√©s client-side)
- Audit r√©gulier s√©curit√©
- Conformit√© loi Fran√ßaise/OTAN

**Fournisseurs Certifi√©s SecNumCloud 2025** :

#### **S3NS (Thales Digital Security + Google)**
- Technologie : GCP Vertex AI + Infrastructure
- Op√©ration : Thales (fran√ßais)
- Certification : SecNumCloud 3.2
- Use case : Donn√©es tr√®s sensibles + besoin IA g√©n√©rative
- Pricing : +30% vs GCP public (~$9.75/To BigQuery vs $6.25)

#### **Bleu (Orange + Capgemini + Microsoft)**
- Technologie : Azure
- Op√©ration : Orange (fran√ßais, op√©rateur telco)
- Certification : SecNumCloud 3.2
- Use case : Donn√©es tr√®s sensibles + √©cosyst√®me Microsoft
- Pricing : +25% vs Azure public

**Cas d'Utilisation SecNumCloud** :
- Minist√®res, Arm√©e
- Donn√©es patients sant√©
- Donn√©es clients banques
- Infrastructure critique (eau, √©lectricit√©)

**Important** : Les donn√©es quittent JAMAIS serveurs europ√©ens. Microsoft/Google ne peuvent pas acc√©der.

---

## CHAPITRE 3 : LE CLOUD PRIV√â (ON-PREMISE)

Quand vous poss√©dez le mat√©riel mais voulez l'agilit√© "cloud-like".

### 3.1 OpenStack ‚Äì L'Industriel

**D√©finition** : OS complet pour datacenter. √âquivalent de "construire votre propre AWS".

#### **Architecture**
```
OpenStack Stack (Modular)
‚îú‚îÄ Nova        : Compute (VMs)
‚îú‚îÄ Neutron     : Networking (VPC-like)
‚îú‚îÄ Cinder      : Block Storage
‚îú‚îÄ Glance      : Image Repository
‚îú‚îÄ Keystone    : Identity (AD-like)
‚îú‚îÄ Horizon     : Web Dashboard
‚îî‚îÄ Swift       : Object Storage (S3-like)
```

#### **Pour Qui ?**
- **Telcos** (Vodafone, Orange) : Infrastructure > 100 n≈ìuds
- **Big Tech** (eBay, Airbnb) : Co√ªts op√©ratoires > $1M/an
- **Super-computers** (CERN, NERSC) : Contr√¥le total infrastructure

#### **Avantages**
- Contr√¥le complet : Donn√©es on-prem, aucun vendor lock-in
- Co√ªt scaling : Co√ªt marginal tr√®s bas apr√®s CAPEX initial
- Customization : Int√©gration AD, LDAP, firewall propre

#### **Inconv√©nients (CRITIQUES)**
- Installation : 6-12 mois int√©gration compl√®te
- √âquipe IT : Minimum 5-10 FTE dedic√©es (full-time)
- Maintenance "Day 2" : Patches, upgrades, troubleshooting constant
- ROI : Break-even 5-7 ans minimum
- Risque : Si √©quipe parts, infrastructure peut devenir "dark matter"

#### **Co√ªts R√©alistes OpenStack**

| √âl√©ment | Co√ªt |
|---------|------|
| Hardware (20 n≈ìuds, 10TB storage) | ‚Ç¨250k |
| Installation & int√©gration (6 mois) | ‚Ç¨300k |
| √âquipe IT (5 FTE √ó ‚Ç¨50k/an) | ‚Ç¨250k/an |
| Maintenance/support (Canonical, etc.) | ‚Ç¨50k/an |
| **5-ans TCO** | **‚Ç¨1.8M** |

---

### 3.2 Proxmox VE ‚Äì L'Accessible

**D√©finition** : Solution de virtualisation open-source bas√©e Debian. "OpenStack pour les PME".

#### **Architecture Simple**
```
Proxmox
‚îú‚îÄ Hypervisor KVM (VMs - Linux/Windows)
‚îú‚îÄ Container LXC (lightweight, fast)
‚îî‚îÄ Web UI (intuitive, manageable)
```

#### **Pour Qui ?**
- **PME** (<50 serveurs) : Budget < ‚Ç¨100k
- **Universit√©s** : Labos p√©dagogiques, co√ªt √©tudiant friendly
- **Startups** : Contr√¥le infra propre, co√ªts variables
- **Homelabs** : Enthousiastes infrastructure

#### **Avantages (R√âELS)**
- Installation : 15-20 min ISO boot, setup complet
- Complexit√© : Interface web intuitive, Python/Bash pour scripts
- Co√ªt marginal : Juste √©lectricit√© + renouvellement hardware (5-7 ans)
- Ecosystem : Documentation excelente, communaut√© active
- Flexibilit√© : VMs + Containers dans m√™me cluster

#### **Inconv√©nients**
- Pas de "cloud-native" automatis√© : Pas Kubernetes natif (ajout manuel)
- Support : Communaut√© (gratuit) vs Proxmox Inc (‚Ç¨‚Ç¨ premium)
- Scaling r√©seau : Management 1-2 admins OK; 10+ admins = croissance management
- Single pane glass : Dashboard moins centralis√© que cloud public

#### **Co√ªts R√©alistes Proxmox**

| √âl√©ment | Co√ªt |
|---------|------|
| Hardware (2 n≈ìuds √ó ‚Ç¨8k) | ‚Ç¨16k |
| Installation & setup (1 week) | ‚Ç¨3k |
| √âquipe IT (0.5 FTE √ó ‚Ç¨50k/an) | ‚Ç¨25k/an |
| Maintenance (domaines, updates) | ‚Ç¨5k/an |
| **5-ans TCO** | **‚Ç¨155k** |

**Break-even vs AWS** : 155k / (‚Ç¨60/mois AWS √ó 12) = ~22 mois. **Apr√®s 2 ans, Proxmox meilleur choix pour charges stables.**

---

### 3.3 Apache CloudStack

**D√©finition** : Alternative √† OpenStack, "plus simple mais moins puissante".

**Positionnement**
- Cas d'usage : **H√©bergeurs de taille moyenne** vendant VPS aux clients
- Complexit√© : Monolithique, moins flexible qu'OpenStack mais d√©ploiement plus rapide
- Entreprises : Quelques MSPs fran√ßaises (rare)

**Comparaison OpenStack vs CloudStack vs Proxmox**

| Crit√®re | OpenStack | CloudStack | Proxmox |
|---------|-----------|-----------|---------|
| Taille min cluster | 10+ n≈ìuds | 3+ n≈ìuds | 1 n≈ìud |
| Complexit√© install | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê |
| Services offerts | 10+ | 5 | 2 |
| √âquipe IT requise | 5-10 FTE | 2-3 FTE | 0.5 FTE |
| Break-even | 5-7 ans | 2-3 ans | 1-2 ans |
| Community | Massive | Petite | Tr√®s active |
| √çdeal pour | Telcos | MSPs | PMEs |

---

## CHAPITRE 4 : MATRICE DE D√âCISION & CAS D'USAGE

### 4.1 M√©thode C.L.O.U.D. (Decision Framework)

Quand vous devez choisir plateforme cloud, posez-vous :

**C ‚Äì Co√ªt (TCO 5 ans)**
- Cloud Public = OPEX (‚Ç¨/mois variable)
- Cloud Priv√© = CAPEX (investissement up-front) + OPEX (exploitation)
- Calcul : (‚Ç¨/mois √ó 12 √ó 5 ans) + migration costs
- Decision : Si scaling <2x = priv√© meilleur; >5x = public meilleur

**L ‚Äì L√©gal (Conformit√© & Donn√©es Sensibles)**
- Donn√©es non-sensibles (marketing, analytics) ‚Üí AWS/Azure/GCP OK
- Donn√©es sensibles (health, banking, PII) ‚Üí Souverain ou Priv√© OBLIGATOIRE
- Compliance crit√®re : RGPD, SecNumCloud, Cloud Act
- Decision : Si sant√©/d√©fense/banque ‚Üí Souverain (S3NS/Bleu) ou Priv√©

**O ‚Äì Ops (Comp√©tences IT)**
- Cloud Public = Faible management, AWS/Azure/GCP g√®re infrastructure
- Proxmox = 0.5 FTE admin, apprentissage 2-3 mois
- OpenStack = 5-10 FTE, apprentissage 6-12 mois
- Decision : Si <5 ing√© ‚Üí cloud public; 5-10 ‚Üí Proxmox; >20 ‚Üí OpenStack

**U ‚Äì Usage (Patterns Utilisation)**
- Scalabilit√© extr√™me (1‚Üí1000 serveurs en 1h) ‚Üí AWS/Azure/GCP MUST
- Charge stable (steady-state) ‚Üí Proxmox optimal
- Bursts temporaires (peaks) ‚Üí Hybrid (Proxmox base + cloud burst)
- Decision : Analyser courbes charge historiques

**D ‚Äì Data Gravity (Co√ªt Migration)**
- Donn√©es actuelles on-prem ‚Üí cloud migration expensive (‚Ç¨/To transit)
- Donn√©es d√©j√† cloud ‚Üí multi-cloud feasible
- Calcul : (Data size √ó $/To) + retraining engineers
- Decision : Si donn√©es √©normes on-prem ‚Üí Proxmox/OpenStack; sinon flexibility

### 4.2 Cas d'Usage R√©els (Profils Entreprise)

#### **Cas 1 : Startup SaaS (FastFood-AI)**

**Profil**
- Secteur : Application web IA (recommandations menu restaurants)
- Donn√©es : Non-sensibles (business metrics, usage logs)
- Scaling : Pr√©vu 1000% an 1, "unicorn track"
- Budget : ‚Ç¨50k infrastructure an1
- √âquipe IT : 1 DevOps freelance

**Recommandation : AWS Public Cloud**

**Justification**
- **Usage** : Scaling extr√™me ‚Üí AWS/Azure/GCP n√©cessaire
- **Co√ªt** : OPEX variable aligne burn rate startup
- **Ops** : 1 DevOps suffit (AWS g√©ra scaling)
- **Data** : Aucun probl√®me donn√©es sensibles
- **C.L.O.U.D. Score** : C(OPEX bon), L(pas critique), O(expert unique), U(scaling fou), D(nulle)

**Architecture Recommand√©e**
```
AWS Region us-east-1
‚îú‚îÄ Application : ECS on Fargate (containers auto-scaled)
‚îú‚îÄ Database : RDS PostgreSQL (managed, backups auto)
‚îú‚îÄ Cache : ElastiCache Redis (session, analytics)
‚îú‚îÄ AI Model : SageMaker Endpoints (real-time inference)
‚îî‚îÄ Analytics : S3 + Athena (data lake)
```

**Budget an 1** : ‚Ç¨12k/mois (‚Ç¨500 app + ‚Ç¨200 DB + ‚Ç¨300 storage + ‚Ç¨100 other)

---

#### **Cas 2 : Grande Banque (Cr√©dit Fran√ßais)**

**Profil**
- Secteur : Donn√©es clients ultra-sensibles (accounts, transactions, ID)
- Donn√©es : Critiques RGPD/DORA (Digital Operational Resilience Act)
- Scaling : Stable (transactions ‚âà constant)
- Budget : Illimit√© pour conformit√©
- √âquipe IT : 50+ ing√©s infrastructure
- R√©gulation : Banque Centrale Fran√ßaise (ACP), CSSF Luxembours

**Recommandation : Cloud de Confiance (Bleu/S3NS) + OpenStack On-Prem**

**Justification**
- **L√©gal** : Donn√©es clients NE QUITTENT JAMAIS France (SecNumCloud obligatoire)
- **Ops** : 50 ing√©s ‚Üí OpenStack d√©ploiement r√©aliste
- **Usage** : Charge stable ‚Üí Priv√© optimis√© co√ªt long-terme
- **Data** : Donn√©es √©normes (PB scale) ‚Üí migrations co√ªteuses
- **C.L.O.U.D. Score** : C(CAPEX √©norme justifi√©), L(L√âGAL = MUST), O(√©quipes √©normes), U(stable), D(donn√©es √©normes)

**Architecture Recommand√©e**
```
Bleu (SecNumCloud)
‚îú‚îÄ Production workloads sensibles (compliance-critical)
‚îú‚îÄ H√©bergement : Paris, audit ANSSI

OpenStack On-Prem (Paris + Lyon)
‚îú‚îÄ D√©veloppement/tests
‚îú‚îÄ Donn√©es "moins sensibles" (marketing, analytics)
‚îú‚îÄ Disaster recovery cluster (asynchrone)

Interconnect : MPLS s√©curis√© France
```

**Budget an 1** : ‚Ç¨5M (CAPEX amortissable + ‚Ç¨500k OPEX)

---

#### **Cas 3 : PME T√©l√©com (Startup ISP)**

**Profil**
- Secteur : Infrastructure r√©seau (vpn, firewall as-a-service)
- Donn√©es : Donn√©es clients sensibles (logs, configurations)
- Scaling : Croissance 30% an (mod√©r√©e)
- Budget : ‚Ç¨200k infrastructure an1
- √âquipe IT : 3 ing√©s (DevOps/Infra/Network)
- Compliance : RGPD, donn√©es UE

**Recommandation : Hybrid (Proxmox On-Prem + Scaleway Cloud)**

**Justification**
- **Co√ªt** : Proxmox base stable (‚Ç¨3k setup) + Scaleway burst scaling flexible
- **Legal** : Donn√©es clients France (Proxmox) + √©ventuels backups Scaleway EU
- **Ops** : 3 ing√©s g√®rent Proxmox facilement + Scaleway documentation excellent
- **Usage** : Charge base steady (Proxmox) + peaks saisonni√®res (Scaleway)
- **Data** : Donn√©es sensibles on-prem (Proxmox), backups cloud (Scaleway)
- **C.L.O.U.D. Score** : C(Hybrid=optimal), L(RGPD ok), O(√©quipe petite), U(burst), D(medium)

**Architecture Recommand√©e**
```
Proxmox Cluster (2 n≈ìuds, Paris datacenter)
‚îú‚îÄ Production VPN/Firewall (steady load)
‚îú‚îÄ Database PostgreSQL principal
‚îî‚îÄ Monitoring/Logging local

Scaleway (Backup + Burst)
‚îú‚îÄ Hot standby VPN secondaire (basculement auto)
‚îú‚îÄ Object storage (S3 API) pour logs archiv√©s
‚îî‚îÄ Kubernetes cluster (GKE-like) pour nouveaux projets

Synchronization : Rsync + Ansible (hourly)
```

**Budget an 1** : ‚Ç¨150k (Proxmox hardware ‚Ç¨80k + Scaleway ‚Ç¨700/mois + 1 FTE extra)

---

#### **Cas 4 : Universit√© Fran√ßaise (Labos Recherche)**

**Profil**
- Secteur : Recherche acad√©mique (simulations physique, genomique)
- Donn√©es : Donn√©es publiques (publications, datasets acad√©miques)
- Scaling : Tr√®s variable (bursts calculs ~100 CPU, puis quiescent)
- Budget : ‚Ç¨30k/an infrastructure
- √âquipe IT : 1 admin temps partiel
- Compliance : Aucune r√©glementation sensible

**Recommandation : Proxmox Community + GCP BigQuery (Spot Pricing)**

**Justification**
- **Co√ªt** : Proxmox ultra low-cost, GCP Spot ML cheap pour calculs
- **Ops** : 1 admin g√®re Proxmox; chercheurs utilisent GCP console
- **Usage** : Bursts calculs intensifs ‚Üí GCP TPU/GPU spot pricing (-80% vs on-demand)
- **Legal** : Aucune restriction donn√©es publiques
- **Data** : Peu donn√©es persistantes (r√©sultats publi√©s)
- **C.L.O.U.D. Score** : C(tr√®s bas), L(n/a), O(equipe minuscule), U(burst), D(nul)

**Architecture Recommand√©e**
```
Proxmox Cluster (Universit√©, 2 n≈ìuds)
‚îú‚îÄ VMs chercheurs (acc√®s via SSH)
‚îú‚îÄ Logiciels open-source (GROMACS, BLAST, etc.)
‚îî‚îÄ Donn√©es inputs/outputs stockage local

GCP Vertex AI (Spot Instances)
‚îú‚îÄ ML training (GPUs T4/V100 spot : ‚Ç¨0.14/h vs ‚Ç¨0.35 on-demand)
‚îú‚îÄ BigQuery (analytics)
‚îî‚îÄ Cloud Storage (donn√©es partag√©es avec Google)

Integration : gsutil sync (chercheurs t√©l√©chargent r√©sultats)
```

**Budget an 1** : ‚Ç¨35k (Proxmox hardware ‚Ç¨20k amortissable, GCP ‚Ç¨500/mois)

---

### 4.3 Matrice Synth√©tique de D√©cision

```
                    ‚îÇ Non-sensible ‚îÇ Sensible RGPD      ‚îÇ Ultra-critique ‚îÇ
                    ‚îÇ   Scalable   ‚îÇ   Scalable         ‚îÇ      Stable    ‚îÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
Small Budget        ‚îÇ AWS Free     ‚îÇ Scaleway           ‚îÇ Proxmox        ‚îÇ
(<‚Ç¨50k/an)          ‚îÇ GCP Free     ‚îÇ (startup-friendly) ‚îÇ (homelab)      ‚îÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
Medium Budget       ‚îÇ AWS Standard ‚îÇ OVHcloud           ‚îÇ Proxmox        ‚îÇ
(‚Ç¨50k‚Äì500k/an)      ‚îÇ Azure/GCP    ‚îÇ Scaleway           ‚îÇ Hybrid Proxmox ‚îÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
Large Budget        ‚îÇ AWS/Azure    ‚îÇ Bleu/S3NS          ‚îÇ OpenStack      ‚îÇ
(>‚Ç¨500k/an)         ‚îÇ Multi-region ‚îÇ (compliance)       ‚îÇ On-Prem        ‚îÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
```

---

## GLOSSAIRE

| Terme | D√©finition |
|-------|-----------|
| **CAPEX** | Capital Expenditure : investissement infrastructure (hardware) |
| **OPEX** | Operating Expenditure : co√ªts exploitation r√©currents (‚Ç¨/mois) |
| **TCO** | Total Cost of Ownership : co√ªt global 5 ans (CAPEX + OPEX) |
| **SLA** | Service Level Agreement : garantie uptime (ex: 99.99%) |
| **Vendor Lock-in** | D√©pendance fournisseur rendant migration difficile/co√ªteuse |
| **Hybrid Cloud** | Combination cloud public + infrastructure on-prem |
| **SecNumCloud** | Label ANSSI "cloud de confiance" France (donn√©es sensibles) |
| **RGPD** | Regulation G√©n√©rale Protection Donn√©es (UE) |
| **Cloud Act** | Loi US permettant autorit√©s acc√©der donn√©es US servers |
| **IaaS** | Infrastructure as a Service (VMs, storage) |
| **PaaS** | Platform as a Service (App services, databases manag√©es) |
| **SaaS** | Software as a Service (Salesforce, Office 365) |

---

## RESSOURCES & LIENS

**Cloud Publics Officiels**
- AWS : https://aws.amazon.com/fr/
- Azure : https://azure.microsoft.com/fr-fr/
- GCP : https://cloud.google.com/

**Acteurs Souverains**
- OVHcloud : https://www.ovhcloud.com/fr/
- Scaleway : https://www.scaleway.com/fr/
- Bleu (Cloud de Confiance) : https://www.bleu.fr/
- S3NS (Cloud de Confiance) : https://www.s3ns.eu/

**Open Source**
- Proxmox : https://pve.proxmox.com/wiki/
- OpenStack : https://www.openstack.org/

**Calculateurs Co√ªts**
- AWS Pricing Calculator : https://calculator.aws/
- Azure Pricing Calculator : https://azure.microsoft.com/fr-fr/pricing/calculator/
- GCP Pricing Calculator : https://cloud.google.com/products/calculator

**Tutoriels & Documentation**
- FreeCodeCamp AWS : https://www.youtube.com/freecodecamp (AWS course)
- Udemy Azure fundamentals : AZ-900 preparation
- Proxmox tutorials : https://pve.proxmox.com/wiki/Main_Page

---

## POINTS CL√âS √Ä RETENIR

‚úÖ **Les 3 Hyperscalers** :
- AWS = G√©n√©raliste dominant (30% march√©), complexit√© haute
- Azure = Int√©grateur Microsoft (20%), hybrid cloud champion
- GCP = Sp√©cialiste IA 2025 (13%), data analytics superior

‚úÖ **Souverainet√© 2026** :
- Cloud Act = autorit√©s US peuvent acc√©der donn√©es US servers
- SecNumCloud = label ANSSI pour donn√©es critiques France
- Bleu & S3NS = offres "cloud de confiance" op√©r√©es France

‚úÖ **Open Source** :
- OpenStack = mastodonte puissant, 5-7 ans ROI, 10+ FTE
- Proxmox = sweet spot PME/labos, 1-2 ans ROI, 0.5 FTE ‚≠ê
- CloudStack = niche MSP, rarement vu France

‚úÖ **Formules Calcul** :
```
TCO 5 ans = (‚Ç¨/mois √ó 12 √ó 5) + migration + √©quipe
Break-even Proxmox = CAPEX / (cloud ‚Ç¨/mois √ó 12)
Exemple : ‚Ç¨120k √∑ (‚Ç¨600/mois √ó 12) = ~17 mois
```

‚úÖ **Apr√®s ce module, vous devez** :
1. Justifier choix cloud pour organisation r√©elle
2. Estimer co√ªts 5 ans (CAPEX vs OPEX)
3. Identifier crit√®res l√©gaux (RGPD, SecNumCloud)
4. Comparer forces/faiblesses AWS/Azure/GCP
5. D√©cider public vs priv√© vs hybrid bas√© data gravity

---

## PROCHAINE √âTAPE

**Module 3 : Architecture Cloud & Infrastructure as Code**
- Deep dive VPC (Virtual Private Cloud)
- Terraform & Ansible (automatisation)
- Haute Disponibilit√© & Disaster Recovery
- Kubernetes introduction
- Cost optimization

# SUPPORT DE TRAVAUX PRATIQUES (TP2)

**Dur√©e :** 2 heures  
**Sc√©nario :** "Duel d'Architectes"

---

## INTRODUCTION

Vous √™tes **consultant junior en architecture cloud**. Un client h√©site entre :
- **Option 1** : D√©ployer infrastructure chez Google Cloud (public cloud)
- **Option 2** : Monter serveur Proxmox on-prem (private cloud)

**Mission** : Prototyper LES DEUX en parall√®le et r√©diger rapport de comparaison.

**Objectif p√©dagogique** : 
- Exp√©rimenter d√©ploiement cloud public (AWS/GCP)
- D√©ployer infrastructure on-prem (Proxmox/VirtualBox)
- Comparer temps, co√ªt, complexit√©, contr√¥le
- R√©diger justification architecturale

---

## TP2.1 : CLOUD PUBLIC (AWS/GCP)

### **Dur√©e** : 1 heure
### **Pr√©-requis**
- Compte Google Cloud / AWS (FREE TIER)
- Terminal SSH client (PuTTY Windows / Terminal macOS-Linux)
- Navigateur web moderne
- Pair(e) pour travail 2 personnes recommand√©

### **Sc√©nario**
Vous devez d√©ployer **serveur web Apache avec une page HTML** pour startup "FastFood-AI" (recommandations IA pour menus restaurants).

---

### **√âTAPE 1 : Cr√©ation Compte Cloud & Activation Free Tier**

#### **Option A : Google Cloud Platform**

**A.1 : Signup GCP**
1. Aller https://cloud.google.com/
2. Cliquer "Try for free" (coin haut-droit)
3. Remplir formulaire Google Account (ou cr√©er nouveau)
   - Email √©tudiant (universit√©) recommand√©
   - V√©rification par SMS/appel (Google s√©curit√©)
4. Saisir carte bancaire (charge ‚Ç¨0, jamais d√©bit√© sans accord)
5. Approuver conditions : "$300 cr√©dits gratuit, 12 mois"
6. Vous √™tes maintenant sur **GCP Free Tier** ‚úì

**A.2 : V√©rifier Quota Free Tier**
```
GCP Console ‚Üí Billing ‚Üí Budget
‚Üí V√©rifier $300 cr√©dits visibles
‚Üí V√©rifier "Free Tier" reste 11 mois 20 jours
```

#### **Option B : Amazon AWS (Alternative)**

**B.1 : Signup AWS**
1. Aller https://aws.amazon.com/fr/
2. Cliquer "Cr√©er un compte AWS"
3. Remplir formulaire standard + adresse France
4. **IMPORTANT (Juillet 2025+)** : Choisir **FREE PLAN** √† signup
   ```
   Ancienne offre (obsol√®te) : 12 mois gratuits
   Nouvelle offre (juillet 2025+) : $200 cr√©dits, 6 mois max
   ‚Üí Choisir FREE PLAN = 0 risque facturation
   ```
5. V√©rifier email confirmation
6. Vous √™tes maintenant sur **AWS Free Tier** ‚úì

**B.2 : V√©rifier Quota Free Tier**
```
AWS Console ‚Üí Billing ‚Üí Cost Management
‚Üí V√©rifier $200 cr√©dits visibles
‚Üí V√©rifier "Free Plan" expire dans ~6 mois
```

---

### **√âTAPE 2 : Lancer Instance Compute (Serveur Virtual Machine)**

#### **Option A : Google Cloud Compute Engine**

**A.1 : Naviguer Compute Engine**
```
GCP Console ‚Üí menu hamburger (haut-gauche)
‚Üí Compute Engine
‚Üí Instances VM
```

**A.2 : Cr√©er Instance**
1. Cliquer "Create Instance"
2. Remplir formulaire :
   ```
   Name                : webapp-fastfood-01
   Region              : europe-west1 (Belgique, proche France)
   Zone                : europe-west1-b
   Machine Type        : e2-micro (1 vCPU, 1GB RAM) ‚Üê FREE TIER
   Operating System    : Debian 12
   Firewall Rules      : ‚úÖ Allow HTTP
                         ‚úÖ Allow HTTPS
   ```
3. Cliquer "Create" (attendre 30-60 secondes)
4. Instance lanc√©e ‚úì

**A.3 : Se Connecter SSH**
1. Dans liste instances, cliquer instance "webapp-fastfood-01"
2. Cliquer "SSH" (fen√™tre terminal web s'ouvre)
3. V√©rifier prompt `username@hostname:~$`

#### **Option B : Amazon AWS EC2**

**B.1 : Naviguer EC2**
```
AWS Console ‚Üí Services ‚Üí EC2
‚Üí Instances (menu gauche)
```

**B.2 : Cr√©er Instance**
1. Cliquer "Launch Instance"
2. Remplir AMI & Config :
   ```
   Name                : webapp-fastfood-01
   AMI                 : Ubuntu 22.04 LTS (Free Tier eligible)
   Instance Type       : t2.micro ‚Üê FREE TIER
   Region              : eu-west-1 (Irlande, proche France)
   Network             : Default VPC
   Security Group      : Create new
     - Allow SSH (port 22)
     - Allow HTTP (port 80)
   Key Pair            : Create "fastfood-key" (sauvegarder .pem)
   ```
3. Cliquer "Launch Instance"
4. Attendre status "running" (2-3 min)
5. Instance lanc√©e ‚úì

**B.3 : Se Connecter SSH**
```bash
# T√©l√©charger cl√© fastfood-key.pem
# Changer permissions (Linux/Mac) :
chmod 400 ~/Downloads/fastfood-key.pem

# R√©cup√©rer IP public instance (AWS Console)
# Ex : 52.18.123.45

# Se connecter :
ssh -i ~/Downloads/fastfood-key.pem ubuntu@52.18.123.45
```

---

### **√âTAPE 3 : Installer Apache & D√©ployer Application**

#### **M√©thode A : Installation Manuelle (pas Recommend√©)**

**A.1 : Mettre √† jour OS**
```bash
$ sudo apt update
$ sudo apt upgrade -y
```

**A.2 : Installer Apache**
```bash
$ sudo apt install -y apache2
$ sudo systemctl start apache2
$ sudo systemctl enable apache2  # D√©marrage auto

# V√©rifier status :
$ sudo systemctl status apache2
# Output : active (running) ‚úì
```

**A.3 : Cr√©er Page HTML Personnalis√©e**
```bash
# Cr√©er fichier HTML :
$ sudo nano /var/www/html/index.html
```

Copier-coller contenu HTML :
```html
<!DOCTYPE html>
<html>
<head>
    <title>FastFood-AI | Menu Recommendations</title>
    <style>
        body { font-family: Arial; margin: 40px; background: #f0f0f0; }
        .header { background: #ff6b6b; color: white; padding: 20px; border-radius: 5px; }
        .content { background: white; padding: 20px; margin-top: 20px; }
        .footer { text-align: center; color: #666; margin-top: 30px; font-size: 12px; }
    </style>
</head>
<body>
    <div class="header">
        <h1>üçî FastFood-AI</h1>
        <p>Recommandations Intelligentes de Menu</p>
    </div>
    <div class="content">
        <h2>Bienvenue!</h2>
        <p>Cette application utilise l'IA pour recommander menus personnalis√©s.</p>
        <p><strong>Status :</strong> ‚úÖ Serveur en ligne</p>
        <p><strong>Date :</strong> <script>document.write(new Date().toLocaleString('fr-FR'));</script></p>
    </div>
    <div class="footer">
        <p>D√©ploy√© sur Cloud Public (Google/AWS) - 2026</p>
    </div>
</body>
</html>
```

**A.4 : Valider Apache Fonctionne**
```bash
# Obtenir IP publique instance (depuis GCP/AWS Console)
# Ouvrir navigateur : http://[IP_PUBLIQUE]
# V√©rifier page HTML affich√©e ‚úì
```

#### **M√©thode B : Automatisation User Data (Recommand√©)**

**B.1 : Cr√©er Script de D√©marrage**

Cr√©er fichier `startup.sh` sur ordinateur local :
```bash
#!/bin/bash
# Mise √† jour OS
apt update && apt upgrade -y

# Installer Apache
apt install -y apache2

# D√©marrer Apache
systemctl start apache2
systemctl enable apache2

# Cr√©er page HTML
cat > /var/www/html/index.html << 'EOF'
<!DOCTYPE html>
<html>
<head>
    <title>FastFood-AI | Menu Recommendations</title>
    <style>
        body { font-family: Arial; margin: 40px; background: #f0f0f0; }
        .header { background: #ff6b6b; color: white; padding: 20px; }
        .content { background: white; padding: 20px; margin-top: 20px; }
        .footer { text-align: center; color: #666; margin-top: 30px; }
    </style>
</head>
<body>
    <div class="header"><h1>üçî FastFood-AI</h1></div>
    <div class="content">
        <h2>‚úÖ Serveur en ligne</h2>
        <p>Page servie automatiquement via User Data!</p>
    </div>
</body>
</html>
EOF
```

**B.2 : Utiliser User Data GCP**
1. Lors cr√©ation instance "webapp-fastfood-01"
2. D√©rouler "Advanced options"
3. Dans "Metadata" ‚Üí ajouter cl√© "startup-script"
4. Coller contenu startup.sh
5. Cr√©er instance
6. Apache d√©marre automatiquement! ‚úì

**B.3 : Utiliser User Data AWS**
1. Lors "Launch Instance" step 3 (Advanced Details)
2. D√©plier "User data"
3. Coller contenu startup.sh (sans `#!/bin/bash`)
4. Lancer instance
5. Apache d√©marre automatiquement! ‚úì

---

### **√âTAPE 4 : Tests & Validation Web**

**T.1 : Acc√©der Serveur Web**
```
Ouvrir navigateur : http://[IP_PUBLIQUE_INSTANCE]
V√©rifier page HTML FastFood-AI s'affiche ‚úì
```

**T.2 : Tester Latence**
```bash
# Depuis terminal local :
$ curl -w "Temps r√©ponse : %{time_total}s\n" http://[IP_PUBLIQUE]
# Output attendu : < 200ms (latence UE)
```

**T.3 : V√©rifier Apache Logs**
```bash
# Depuis SSH instance :
$ sudo tail -20 /var/log/apache2/access.log
# V√©rifier requ√™te HTTP visible
```

---

### **√âTAPE 5 : Gestion Ressources & Cleanup**

#### **CRIT√àRE IMPORTANT : √âviter Facturation**

**√âtape Obligatoire : Arr√™ter Instance**
```
GCP Console ‚Üí Instances ‚Üí webapp-fastfood-01
‚Üí Arr√™ter (STOP button, pas DELETE)

AWS Console ‚Üí Instances ‚Üí webapp-fastfood-01
‚Üí Instance State ‚Üí Stop instance
```

**V√©rifier Quota Restant**
```
GCP Billing ‚Üí Budget ‚Üí V√©rifier $300 cr√©dits - cout instance
AWS Billing ‚Üí Cost Management ‚Üí V√©rifier $200 cr√©dits
```

**Estimation Co√ªt Horaire** :
```
GCP e2-micro  : $0.033/h = environ $0.03 √ó 1h = ‚Ç¨0.03
AWS t2.micro  : $0.0116/h = environ ‚Ç¨0.01 √ó 1h = ‚Ç¨0.01

Ne pas oublier arr√™ter instance!
```

---

### **√âTAPE 6 : Rapport TP2.1**

**R√©diger rapport (1-2 pages)**

**Section 1 : Setup & Pr√©requis (5 min)**
- Cloud utilis√© (GCP / AWS)
- R√©gion deploy√©e
- Machine type
- Co√ªts Free Tier restants

**Section 2 : Installation & D√©ploiement (10 min)**
- Temps installation Apache (du clic "create" √† page web visible)
- Probl√®mes rencontr√©s & solutions
- √âtapes automatisation (User Data) vs manual
- Impact productivit√© automatisation

**Section 3 : Observations (10 min)**
- Latence mesur√©e page load (curl timing)
- Facilit√© dashboard cloud
- Gestion s√©curit√© (firewall, cl√©s SSH)
- √âl√©ments positifs/n√©gatifs

**Section 4 : Consid√©rations Co√ªts (5 min)**
- Co√ªt horaire machine utilis√©e
- Co√ªt stockage donn√©es
- Co√ªt transfert donn√©es (si applicable)
- Estimation co√ªt 1 mois service steady-state

**Notation** : /10 points
- Setup correct ‚úì : /3
- Rapport d√©taill√© ‚úì : /4
- Observations pertinentes ‚úì : /3

---

## TP2.2 : CLOUD PRIV√â (PROXMOX/VIRTUALBOX)

### **Dur√©e** : 1 heure
### **Pr√©-requis**
- Ordinateur avec VirtualBox ou Proxmox install√©
- 8GB RAM libre minimum
- ISO Debian 12 (~600MB)
- Acc√®s r√©seau (t√©l√©chargement ISO)

### **Sc√©nario**
D√©ployer **m√™me serveur web Apache** mais sur infrastructure priv√©e (Proxmox/VirtualBox), comparer exp√©rience vs Cloud Public.

---

### **OPTION A : Proxmox VE (Infrastructure D√©di√©e)**

#### **√âtape 1 : Acc√®s Console Proxmox**

**A.1 : Localiser Proxmox**
- Si Proxmox h√©berg√© sur serveur labo (cas universit√©)
- Acc√©der via navigateur : `https://[IP_PROXMOX]:8006`
- Login : root / password fourni par admin

**A.2 : Interface Proxmox**
```
Haut gauche  : S√©lection node (serveur physique)
Gauche panel : Resources (VMs, Containers, Storage)
Centre       : VM/Container details
Droite       : Console (terminal virtual)
```

#### **√âtape 2 : Cr√©er VM**

**A.2.1 : Cr√©er VM Vide**
1. Haut-droit : "Create VM"
2. Formulaire :
   ```
   Node             : proxmox-node-01 (s√©lectionner)
   Name             : fastfood-webapp
   VMID             : 100 (auto-propos√©)
   OS Type          : Linux
   System           : UEFI (moderne)
   Disk             : 20GB (suffisant pour Debian + Apache)
   RAM              : 2GB (minimum)
   Cores            : 2 vCPU
   Network          : Automatic (bridge vmbr0)
   ```
3. Cliquer "Finish"
4. VM cr√©√©e (√©tat "stopped") ‚úì

**A.2.2 : Attacher ISO Debian**
1. S√©lectionner VM "fastfood-webapp"
2. Hardware ‚Üí CD/DVD Drive
3. Cliquer "Edit" ‚Üí s√©lectionner ISO Debian 12
4. VM maintenant peut booter ISO

#### **√âtape 3 : Installer Debian**

**A.3.1 : Boot sur ISO**
1. S√©lectionner VM "fastfood-webapp"
2. Cliquer "Console" (haut-droit)
3. Cliquer "Start" (boot VM)
4. Installer Debian 12 standard (installation graphique ~15 min)
   ```
   Language        : Fran√ßais (ou English si lisibilit√© pr√©f√©r√©e)
   Disque          : /dev/vda (seul disque)
   Hostname        : fastfood-webapp
   Domain          : local.lan
   Root password   : [cr√©er mot-de-passe]
   User            : student
   User password   : [cr√©er mot-de-passe]
   Mirror           : Oui (installation packages)
   GRUB bootloader : /dev/vda
   ```
5. Installation compl√®te ~15 min, reboot auto

**A.3.2 : Post-Installation**
```bash
# Login shell (root) :
$ sudo apt update
$ sudo apt upgrade -y
$ sudo apt install -y openssh-server

# D√©marrer SSH :
$ sudo systemctl start ssh
$ sudo systemctl enable ssh

# R√©cup√©rer IP VM :
$ ip addr show eth0
# V√©rifier adresse IP (ex: 192.168.100.50)
```

#### **√âtape 4 : Installer Apache (SSH)**

**A.4.1 : Connexion SSH depuis ordinateur local**
```bash
# Terminal local :
$ ssh student@192.168.100.50
# Enter password
$ whoami
# Output : student
```

**A.4.2 : Installer Apache**
```bash
$ sudo apt install -y apache2
$ sudo systemctl start apache2
$ sudo systemctl enable apache2

# V√©rifier :
$ sudo systemctl status apache2
# Output : active (running) ‚úì
```

**A.4.3 : D√©ployer Page HTML**
```bash
$ sudo nano /var/www/html/index.html
```

Copier m√™me HTML que TP2.1 (FastFood-AI page).

**A.4.4 : Tester Acc√®s Web**
```bash
# Depuis ordinateur local :
# Ouvrir navigateur : http://192.168.100.50
# V√©rifier page HTML affich√©e ‚úì
```

---

### **OPTION B : VirtualBox (Ordinateur Personnel)**

#### **√âtape 1 : Cr√©er VM VirtualBox**

**B.1.1 : Cr√©er Machine Virtuelle**
1. VirtualBox ‚Üí "New" (haut-gauche)
2. Formulaire :
   ```
   Name        : fastfood-webapp
   OS          : Linux / Debian 64-bit
   RAM         : 2048 MB
   Disk        : 20GB (VDI, dynamique)
   ```
3. Cliquer "Create"

**B.1.2 : Attacher ISO Debian**
1. S√©lectionner VM "fastfood-webapp"
2. Settings ‚Üí Storage
3. CD/DVD Drive ‚Üí s√©lectionner ISO Debian 12
4. Cliquer "OK"

#### **√âtape 2 : Installer Debian (Identique A.3)**

Suivre **A.3.1 : Boot sur ISO** ‚Üí **A.3.2 : Post-Installation**

#### **√âtape 3 : Installer Apache (Identique A.4)**

Suivre **A.4.1 ‚Üí A.4.4**

---

### **√âTAPE 5 : Comparaison Cloud vs Priv√©**

**Remplir Tableau Comparatif** :

| Crit√®re                            | Cloud Public (GCP/AWS)  | Cloud Priv√© (Proxmox/VBox) | Gagnant |
| ---------------------------------- | ----------------------- | -------------------------- | ------- |
| **Temps d√©ploiement**              | [temps en min]          | [temps en min]             | ?       |
| **Complexit√©**                     | [simple/moyen/complexe] | [simple/moyen/complexe]    | ?       |
| **Contr√¥le infrastructure**        | [oui/non]               | [oui/non]                  | ?       |
| **Scalabilit√© (ajouter serveurs)** | [rapide/lent]           | [rapide/lent]              | ?       |
| **Support/Documentation**          | [Google/AWS]            | [Proxmox Forum]            | ?       |
| **Co√ªt setup initial**             | $200 cr√©dits            | ‚Ç¨50-100 hardware           | ?       |
| **Co√ªt exploitation**              | ‚Ç¨20-50/mois             | ‚Ç¨5-10/mois √©lectricit√©     | ?       |
| **Facilit√© networking**            | [facile/difficile]      | [facile/difficile]         | ?       |
| **Backup/Disaster Recovery**       | [automatique/manuel]    | [automatique/manuel]       | ?       |
| **Temps rendre live en prod**      | [heure/jour/semaine]    | [heure/jour/semaine]       | ?       |

**Instructions Remplissage** :
1. Chaque bin√¥me remplit tableau
2. Justifier chaque r√©ponse (1-2 lignes)
3. Identifier forces/faiblesses chaque approche

---

### **√âTAPE 6 : Rapport TP2.2**

**R√©diger rapport (2-3 pages)**

**Section 1 : Infrastructure Setup (10 min)**
- Plateforme utilis√©e (Proxmox vs VirtualBox)
- Configuration hardware (RAM, CPU, disque)
- Syst√®me exploitation d√©ploy√©

**Section 2 : Processus Installation (15 min)**
- √âtapes chronologiques (cr√©ation VM ‚Üí Apache live)
- Temps total (en minutes)
- Difficult√©s rencontr√©es
- Comparaison vs Cloud Public (TP2.1)

**Section 3 : R√©sultats Performance (10 min)**
- Latence page load (curl timing)
- Stabilit√© Apache
- Utilisations ressources VM (htop)
- Observation interface Proxmox/VBox

**Section 4 : Analyse Comparaison (15 min)**
- Tableau comparatif complet
- Cas d'usage optimal Cloud Public vs Priv√©
- Recommandation architecture startup "FastFood-AI"
  - Justifier choix (co√ªts 5 ans, scaling)

**Notation** : /10 points
- Infrastructure running ‚úì : /3
- Rapport complet ‚úì : /4
- Analyse comparaison ‚úì : /3

---

## √âVALUATION GLOBALE TP2.1 + TP2.2

**Grille √âvaluation Enseignant** (/20 points total)

| Aspect | Points | Commentaires |
|--------|--------|--------------|
| **TP2.1 Ex√©cution (Cloud)** | /5 | Instance web live, rapport d√©taill√© |
| **TP2.2 Ex√©cution (Priv√©)** | /5 | Proxmox/VBox fonctionnel, rapport complet |
| **Tableau Comparatif** | /5 | Tous crit√®res remplis, justifications valides |
| **Recommandation Architecture** | /5 | D√©cision justifi√©e (Cloud vs Priv√©), CAPEX/OPEX coh√©rents |
| **TOTAL** | **/20** | |


---

## RESSOURCES √âTUDIANTS

**Google Cloud Platform**
- Acc√®s Free Tier : https://cloud.google.com/
- Documentation GCP : https://cloud.google.com/docs
- Tutoriel SSH GCP : https://cloud.google.com/compute/docs/instances/connecting-to-instance

**Amazon AWS**
- Acc√®s Free Tier : https://aws.amazon.com/fr/
- Documentation EC2 : https://docs.aws.amazon.com/ec2/
- AWS Free Tier Alertes : https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/free-tier.html

**Proxmox**
- Documentation : https://pve.proxmox.com/wiki/
- Forum Support : https://forum.proxmox.com/
- Tutoriels Fran√ßais : Disponibles universit√© (demander admin)

**VirtualBox**
- T√©l√©chargement : https://www.virtualbox.org/
- Manuel Utilisateur : https://www.virtualbox.org/manual/

**Debian Linux**
- T√©l√©charger ISO : https://www.debian.org/releases/
- Documentation Debian : https://wiki.debian.org/

---

## CONSEILS SUCC√àS

‚úÖ **Pour TP2.1 (Cloud)**
- Sauvegarder cl√©s SSH (AWS) dans endroit s√ªr
- Arr√™ter instance IMM√âDIATEMENT apr√®s TP (√©viter charges)
- Tester User Data script en local avant (syntax errors)
- Utiliser FREE PLAN AWS (z√©ro risque facturation)

‚úÖ **Pour TP2.2 (Priv√©)**
- T√©l√©charger ISO Debian avant TP (internet labo parfois lent)
- Proxmox admin : obtenir access credentials 1 jour avant
- VirtualBox : v√©rifier 8GB RAM libre (installer autres apps)
- Prendre screenshot topologie finale (preuve fonctionnement)

‚úÖ **Rapport Comparatif**
- √ätre objectif (pas "cloud toujours meilleur")
- Chaque cas d'usage a r√©ponse diff√©rente
- Quantifier m√©triques (temps en minutes, co√ªts en euros)
- Justifier recommandation avec donn√©es TP

---

## FAQ TP2.1 & TP2.2

**Q: Compte Google/AWS prend combien de temps approuver?**  
A: 5-10 min en g√©n√©ral (v√©rification SMS/appel).

**Q: Comment retrouver IP publique instance?**  
A: GCP Console ‚Üí Instances ‚Üí colonne "External IP"  
AWS Console ‚Üí Instances ‚Üí colonne "Public IPv4 address"

**Q: User Data script ne s'ex√©cute pas?**  
A: V√©rifier logs : `/var/log/cloud-init-output.log` (GCP)  
AWS : `/var/log/cloud-init.log` ‚Üí debug erreurs script

**Q: Proxmox pas accessible, "connexion refus√©e"?**  
A: V√©rifier adresse IP node (demander admin)  
V√©rifier firewall permet port 8006
V√©rifier credentials correct

**Q: Page Apache n'affiche rien (erreur 403)?**  
A: V√©rifier permissions fichier HTML  
`sudo chmod 644 /var/www/html/index.html`

**Q: Combien co√ªte un jour de serveur cloud?**  
A: GCP e2-micro : $0.033/h = ~‚Ç¨0.70/jour  
AWS t2.micro : $0.0116/h = ~‚Ç¨0.25/jour  
(IMPORTANT : arr√™ter instance apr√®s TP!)

**Q: Peut-on red√©ployer plusieurs fois m√™me instance?**  
A: OUI. GCP/AWS permettent cr√©ation/suppression illimit√©e dans Free Tier.  
Proxmox: cr√©er nouvelle VM (m√™me VM multiple fois = mauvaise pratique)

---

## POINTS CL√âS √Ä RETENIR (TP)

‚úÖ **D√©ploiement Cloud Public** :
- Point-and-click interface, lancement ~1 min
- Co√ªts transparents, scaling illimit√©
- Support massive (milliers tutorials)
- Vendor lock-in potentiel (services propri√©taires)

‚úÖ **D√©ploiement Cloud Priv√©** :
- Installation ~30 min (Proxmox) vs ~15 min (VirtualBox)
- Contr√¥le total infrastructure, donn√©es on-prem
- Co√ªts CAPEX initial, puis OPEX faible
- √âquipe IT requise pour maintenance

‚úÖ **Aucun n'est "meilleur"** :
- Startup : Cloud Public (scaling crucial, √©quipe r√©duite)
- PME stable : Proxmox (contr√¥le, co√ªts pr√©visibles)
- Banque critique : Priv√© (SecNumCloud, s√©curit√© absolue)
- Universit√© labos : Proxmox (budget, apprentissage)

# MODULE 3 : INFRASTRUCTURE AS CODE (IaC)
## Support de Cours √âtudiant ‚Äì Licence 3 BUT R&T
**Date :** Janvier 2026     
**Pr√©requis :** Modules 1-2 valid√©s, Linux Bash, YAML, concepts r√©seau

---

## TABLE DES MATI√àRES

1. [Introduction : La fin du "ClickOps"](#introduction)
2. [Chapitre 1 : Concepts Fondamentaux IaC](#chapitre-1)
3. [Chapitre 2 : Terraform ‚Äì Provisionning Infrastructure](#chapitre-2)
4. [Chapitre 3 : Ansible ‚Äì Configuration Post-D√©ploiement](#chapitre-3)
5. [Chapitre 4 : Architecture Cloud R√©seau](#chapitre-4)
6. [Chapitre 5 : Haute Disponibilit√© & R√©silience](#chapitre-5)
7. [Cas d'√âtude : TechNova Phase 2](#cas-detude)
8. [Glossaire & Ressources](#glossaire)

---

## INTRODUCTION : La fin du "ClickOps" 

Jusqu'√† pr√©sent, vous avez cr√©√© des serveurs manuellement via la console AWS/GCP. C'est amusant pour **un seul serveur**. C'est un cauchemar pour **50**. Et c'est **impossible** pour **1000**.

Imaginez que votre entreprise doit red√©ployer son infrastructure en 15 minutes apr√®s une catastrophe. Comment feriez-vous manuellement ? Clicks, clics, clics... Pendant ce temps, vos clients attendent. Pendant ce temps, vous perdez de l'argent.

**L'Infrastructure as Code (IaC)** est la r√©ponse.

### D√©finition

L'Infrastructure as Code est la **pratique consistant √† g√©rer l'infrastructure informatique via des fichiers de d√©finition**, plut√¥t que par la configuration manuelle via une interface graphique (IaC vs ClickOps).

**Analogie du BTP :**
- **ClickOps** = Un artisan qui construit maison apr√®s maison, chaque fois diff√©rente, sans plan.
- **Infrastructure as Code** = Un ing√©nieur qui cr√©e un plan (Terraform), puis une usine le reproduit √† l'identique 1000 fois.

### Pourquoi coder son infrastructure ?

| B√©n√©fice              | Explication                                                                                             |
| --------------------- | ------------------------------------------------------------------------------------------------------- |
| **Reproductibilit√©**  | Je d√©truis mon environnement et le recr√©√© √† l'identique en UNE commande.                                |
| **Versionning (Git)** | Qui a ouvert le port 22 hier ? ‚Üí `git blame` nous donne la r√©ponse. L'infrastructure devient auditable. |
| **Vitesse**           | D√©ployer 100 serveurs en 5 minutes au lieu de 5 jours manuellement (gain de **240x**).                  |
| **Idempotence**       | Peu importe combien de fois j'ex√©cute le code, le r√©sultat est le m√™me.                                 |
| **Disaster Recovery** | Tout a br√ªl√© ? `terraform apply` et c'est reparti.                                                      |
| **Collaboration**     | Plusieurs ing√©nieurs travaillent sur la m√™me infrastructure via Git.                                    |

---

## CHAPITRE 1 : Concepts Fondamentaux IaC

### 1.1 Le Match : D√©claratif vs Imp√©ratif

C'est la **distinction philosophique majeure** en IaC. Ces deux approches r√©pondent au m√™me probl√®me : *Automatiser la gestion de l'infrastructure.* Mais elles le font diff√©remment.

#### Approche IMP√âRATIVE

**Philosophie :** *"Fais ceci, puis fais cela."*

**Outil Type :** Bash, Ansible, Chef

**Analogie GPS  :** "Tourne √† droite, puis fais 500m, puis tourne √† gauche, puis 200m..."

**Exemple Code (Bash) :**
```bash
# Script imp√©ratif : √©tapes √† suivre rigidement
aws ec2 create-vpc --cidr-block 10.0.0.0/16
aws ec2 create-subnet --vpc-id vpc-123 --cidr-block 10.0.1.0/24
aws ec2 create-internet-gateway
# ... et des dizaines d'autres commandes
```

**Probl√®mes :**
- Si une √©tape √©choue √† mi-chemin, l'√©tat est incoh√©rent.
- Relancer le script 2 fois peut cr√©er 2 ressources au lieu de 1.
- Difficile √† d√©boguer.

#### Approche D√âCLARATIVE

**Philosophie :** *"Je veux cet √©tat final."*

**Outil Type :** Terraform, Kubernetes, CloudFormation

**Analogie Taxi :** "Emm√®ne-moi √† la Tour Eiffel." (Le chauffeur g√®re le trajet, les embouteillages, etc.)

**Exemple Code (Terraform) :**
```hcl
# Code d√©claratif : √©tat final d√©sir√©
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
}

resource "aws_subnet" "public" {
  vpc_id     = aws_vpc.main.id
  cidr_block = "10.0.1.0/24"
}

resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
}
# C'est tout. Terraform g√®re les d√©pendances et l'ordre.
```

**Avantages :**
- **Idempotent** : Lancer `terraform apply` 10 fois = m√™me r√©sultat final.
- **D√©pendances automatiques** : Terraform sait que le subnet d√©pend du VPC.
- **Drift detection** : `terraform plan` d√©tecte les changements non autoris√©s.

### 1.2 Idempotence : Le Concept Cl√©

**D√©finition math√©matique :** f(f(x)) = f(x). Si j'applique une fonction deux fois, le r√©sultat est le m√™me.

**En Infrastructure :** 
- J'ai 2 serveurs.
- Mon code d√©clare "je veux 3 serveurs".
- Terraform en ajoute 1, pas 3.
- Je relance mon code : il v√©rifie qu'il y a 3 serveurs, ne cr√©e rien.

**Comparaison :**
```bash
# ‚ùå NON idempotent (Bash imp√©ratif)
echo "Server" >> /etc/hosts
# Ex√©cuter 2 fois = 2 entr√©es dans /etc/hosts

# ‚úÖ Idempotent (Ansible avec Terraform)
resource "aws_instance" "web" {
  count = 3
}
# Ex√©cuter 2 fois = toujours 3 instances
```

### 1.3 Configuration Drift (D√©rive)

**D√©finition :** La "d√©rive de configuration" survient quand l'infrastructure r√©elle diverge du code.

**Scenario Courant :**
1. Je d√©ploie 2 serveurs avec Terraform.
2. Un op√©rateur va √† la console AWS et d√©sactive le monitoring sur un serveur.
3. Mon code dit "2 serveurs avec monitoring" mais la r√©alit√© en a qu'1.
4. C'est la **d√©rive**.

**Solution :**
```bash
# D√©tecte les d√©rives
terraform plan
# Output : "Resource 'aws_instance.web[0]' has drifted. Monitoring is OFF in reality."
```

### 1.4 Le Duo Gagnant : Terraform + Ansible

**Terraform = Provisioning (Infrastructure)**
- Cr√©e les ressources cloud : VPC, Serveurs, Load Balancers, Bases de donn√©es.
- **D√©claratif** : "Je veux cet √©tat."
- Temps : quelques secondes √† quelques minutes.

**Ansible = Configuration (Software)**
- Configure l'int√©rieur des serveurs : installe Nginx, d√©ploie code, cr√©e users.
- **Imp√©ratif** : "Fais ces √©tapes."
- Temps : quelques secondes √† quelques minutes.

**Workflow Complet :**
```
Terraform           Ansible
   ‚Üì                  ‚Üì
Cr√©e VPC        ‚Üí  Installe Nginx
Cr√©e Subnet     ‚Üí  Configure Nginx
Cr√©e EC2        ‚Üí  D√©ploie App
Cr√©e SG         ‚Üí  Red√©marre Services
   ‚Üì                  ‚Üì
Infrastructure      Configurable
(Murs/Toit)        (Meubles/Peinture)
```

---

## CHAPITRE 2 : Terraform ‚Äì Provisionning Infrastructure

### 2.1 Qu'est-ce que Terraform ?

Terraform est un **outil open-source** cr√©√© par HashiCorp qui permet de :
1. **Coder** votre infrastructure en HCL (langage lisible).
2. **Planifier** les changements avant de les appliquer.
3. **Appliquer** les changements de fa√ßon idempotente.
4. **D√©truire** compl√®tement une infrastructure.

### 2.2 Le Langage HCL (HashiCorp Configuration Language)

HCL est con√ßu pour √™tre lisible par les humains. Il s'articule autour de **blocs**.

#### Les 4 Blocs Essentiels

```hcl
# 1. TERRAFORM : Meta-configuration
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

# 2. PROVIDER : Qui est le fournisseur cloud ?
provider "aws" {
  region = "eu-west-3"  # Paris
}

# 3. RESOURCE : Quoi cr√©er ?
resource "aws_instance" "mon_serveur" {
  ami           = "ami-0c55b159cbfafe1f0"  # Ubuntu 22.04
  instance_type = "t3.micro"               # Type & puissance
  
  tags = {
    Name = "Mon-Serveur-Web"
  }
}

# 4. OUTPUT : Quoi afficher apr√®s cr√©ation ?
output "instance_ip" {
  value       = aws_instance.mon_serveur.public_ip
  description = "L'IP publique de mon serveur"
}
```

#### Syntaxe Cl√©

| √âl√©ment | Exemple | Explication |
|---------|---------|-------------|
| **String** | `"eu-west-3"` | Cha√Æne de texte entre guillemets |
| **Number** | `3`, `80` | Nombre entier |
| **Boolean** | `true`, `false` | Vrai/faux |
| **List** | `["a", "b", "c"]` | Liste ordonn√©e |
| **Map** | `{ key1 = "val1" }` | Dictionnaire cl√©-valeur |
| **Reference** | `aws_vpc.main.id` | R√©f√©rencer une ressource |
| **Interpolation** | `"Hello ${var.name}"` | Injecter variables dans texte |

### 2.3 Variables : Rendre le Code R√©utilisable

**Sans variables :**
```hcl
resource "aws_instance" "web" {
  instance_type = "t3.micro"  # Cod√© en dur
}
# Probl√®me : pour changer de type, il faut √©diter le code
```

**Avec variables :**
```hcl
# variables.tf
variable "instance_type" {
  type        = string
  default     = "t3.micro"
  description = "Type instance EC2"
}

# main.tf
resource "aws_instance" "web" {
  instance_type = var.instance_type  # R√©f√©renc√©
}

# terraform.tfvars (surcharge)
instance_type = "t3.small"  # Nouveau type sans toucher au code
```

### 2.4 Le Workflow Terraform (4 √©tapes sacro-saintes)

Tout ing√©nieur Terraform r√©p√®te ce mantra :

#### √âTAPE 1 : `terraform init`

**But :** Initialiser le projet, t√©l√©charger les plugins.

```bash
$ terraform init
Initializing the backend...
Downloading plugin: hashicorp/aws v5.0
...
Terraform has been successfully configured!
```

**Fichiers cr√©√©s :**
- `.terraform/` : Dossier plugins (ne pas commiter sur Git)
- `.terraform.lock.hcl` : Versions pr√©cises des providers (√† commiter)

#### √âTAPE 2 : `terraform plan`

**But :** Simuler les changements. C'est votre **filet de s√©curit√©**.

```bash
$ terraform plan
Plan: 8 to add, 0 to change, 0 to destroy.
```

**Signification :**
- `8 to add` : 8 ressources seront cr√©√©es (VPC, Subnet, IGW, SG, Cl√© SSH, 2 instances, Route Table, etc.)
- `0 to change` : Aucun changement sur des ressources existantes.
- `0 to destroy` : Rien ne sera supprim√©.

**√Ä faire TOUJOURS avant `apply` :** Lire le plan et v√©rifier que tout est correct.

#### √âTAPE 3 : `terraform apply`

**But :** Ex√©cuter le plan et cr√©er les ressources.

```bash
$ terraform apply
Do you want to perform these actions? (yes/no)
yes

aws_vpc.main: Creating...
aws_vpc.main: Creation complete after 2s [id=vpc-0123456789]
aws_subnet.public: Creating...
aws_subnet.public: Creation complete after 1s [id=subnet-0123456789]
...
Apply complete! Resources: 8 added.
```

**Fichier cr√©√© :** `terraform.tfstate` (voir section suivante)

#### √âTAPE 4 : `terraform destroy`

**But :** Supprimer **TOUTES** les ressources cr√©√©es par Terraform.

```bash
$ terraform destroy
Destroy: 8 resources?
yes

aws_instance.web[0]: Destroying...
aws_instance.web[1]: Destroying...
...
Destroy complete! Resources: 8 destroyed.
```

‚ö†Ô∏è **CRITIQUE POUR LES CO√õTS :** Ne pas oublier de d√©truire apr√®s les TPs. Sinon, les serveurs continuent √† tourner et vous facturent AWS !

### 2.5 L'√âtat Terraform (.tfstate) : Le Cerveau

**D√©finition :** Terraform cr√©e un fichier `terraform.tfstate`. C'est un **dictionnaire JSON** qui lie votre code √† la r√©alit√© AWS.

**Contenu Simplifi√© :**
```json
{
  "resources": [
    {
      "type": "aws_vpc",
      "name": "main",
      "instances": [
        {
          "attributes": {
            "id": "vpc-0123456789",
            "cidr_block": "10.0.0.0/16"
          }
        }
      ]
    }
  ]
}
```

**Terraform utilise .tfstate pour :**
1. Savoir quelles ressources il g√®re.
2. D√©tecter les d√©rives : "En r√©alit√©, ce VPC a chang√©."
3. Planifier les changements : "Pour passer de 2 √† 3 serveurs, je dois ajouter 1 instance."

### 2.6 ‚ö†Ô∏è DANGER : R√®gles d'Or pour .tfstate

| R√®gle | Explication |
|-------|-------------|
| **Ne JAMAIS modifier manuellement** | Vous risquez de corrompre Terraform. Il ne saura plus ses ressources. |
| **Ne JAMAIS supprimer** | Terraform pense qu'il ne g√®re rien. Il tente de recr√©er les ressources. |
| **Ne JAMAIS commiter sur Git** | Si le fichier contient des secrets (cl√©s d'acc√®s), elles sont publiques. |
| **Utiliser un Remote State** | En production, stocker .tfstate sur S3 avec versioning + chiffrement. |

**Configuration Remote State (Production) :**
```hcl
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "prod/terraform.tfstate"
    region         = "eu-west-3"
    encrypt        = true
    dynamodb_table = "terraform-locks"  # Locking pour travail collaboratif
  }
}
```

### 2.7 Exemple Complet : D√©ployer un VPC + Subnet + IGW + EC2 + SG

**Fichier : main.tf**
```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = "eu-west-3"
}

# Variables
variable "instance_type" {
  default = "t3.micro"
}

variable "instance_count" {
  default = 2
}

# VPC
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  
  tags = { Name = "vpc-devcloud" }
}

# Subnet Public
resource "aws_subnet" "public" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.1.0/24"
  map_public_ip_on_launch = true
  
  tags = { Name = "subnet-public" }
}

# Internet Gateway
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
  
  tags = { Name = "igw-main" }
}

# Route Table (connecte subnet au IGW)
resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id
  
  route {
    cidr_block      = "0.0.0.0/0"
    gateway_id      = aws_internet_gateway.main.id
  }
  
  tags = { Name = "rt-public" }
}

resource "aws_route_table_association" "public" {
  subnet_id      = aws_subnet.public.id
  route_table_id = aws_route_table.public.id
}

# Security Group (Pare-feu)
resource "aws_security_group" "web" {
  vpc_id = aws_vpc.main.id
  
  # Entrant
  ingress {
    from_port   = 22   # SSH
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]  # ‚ö†Ô∏è √Ä restreindre en prod
  }
  
  ingress {
    from_port   = 80   # HTTP
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  # Sortant (tout autoris√©)
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  tags = { Name = "sg-web" }
}

# Cl√© SSH
resource "aws_key_pair" "deployer" {
  key_name   = "deployer-key"
  public_key = file("~/.ssh/id_rsa.pub")  # Votre cl√© publique locale
}

# Instances EC2
resource "aws_instance" "web" {
  count              = var.instance_count
  ami                = "ami-0c55b159cbfafe1f0"  # Ubuntu 22.04 (eu-west-3)
  instance_type      = var.instance_type
  key_name           = aws_key_pair.deployer.key_name
  subnet_id          = aws_subnet.public.id
  security_groups    = [aws_security_group.web.id]
  
  tags = { Name = "web-server-${count.index + 1}" }
}

# Outputs
output "vpc_id" {
  value = aws_vpc.main.id
}

output "instance_ips" {
  value = {
    for i, instance in aws_instance.web :
    instance.tags["Name"] => instance.public_ip
  }
}
```

**Ex√©cution :**
```bash
terraform init
terraform validate
terraform plan
terraform apply
# Output : IPs publiques affich√©es
terraform output instance_ips
# Output :
# {
#   "web-server-1" = "3.121.45.67"
#   "web-server-2" = "3.121.45.68"
# }

# SSH vers un serveur
ssh -i ~/.ssh/id_rsa ubuntu@3.121.45.67

# Nettoyer
terraform destroy
```

---

## CHAPITRE 3 : Ansible ‚Äì Configuration Post-D√©ploiement

### 3.1 Ansible vs Terraform

| Aspect | Terraform | Ansible |
|--------|-----------|---------|
| **R√¥le** | Cr√©er infrastructure (VPC, serveurs) | Configurer l'int√©rieur des serveurs |
| **Approche** | D√©claratif | Imp√©ratif |
| **Agent** | N√©cessite backend distant (S3) | Agentless (SSH seulement) |
| **Langage** | HCL | YAML |
| **Idempotent** | Oui (v√©rification d'√©tat) | Oui (modules idempotents) |
| **Temps d√©ploiement** | Minutes | Secondes |

### 3.2 Structure Ansible

**Troix √©l√©ments cl√©s :**

#### 1. Inventory (Inventaire)

Liste des serveurs √† configurer.

```ini
# hosts.ini
[webservers]
web-1 ansible_host=3.121.45.67 ansible_user=ubuntu
web-2 ansible_host=3.121.45.68 ansible_user=ubuntu

[webservers:vars]
ansible_ssh_private_key_file=~/.ssh/id_rsa
```

#### 2. Playbook

Fichier YAML d√©crivant les t√¢ches √† ex√©cuter.

```yaml
---
- name: Install Nginx
  hosts: webservers
  become: yes  # Utiliser sudo
  
  tasks:
    - name: Update APT
      apt:
        update_cache: yes
    
    - name: Install Nginx
      apt:
        name: nginx
        state: present
    
    - name: Start Nginx
      systemd:
        name: nginx
        state: started
        enabled: yes
```

#### 3. Roles (Optionnel)

R√©utiliser des configurations.

```
roles/
‚îú‚îÄ‚îÄ nginx/
‚îÇ   ‚îú‚îÄ‚îÄ tasks/main.yml
‚îÇ   ‚îú‚îÄ‚îÄ handlers/main.yml
‚îÇ   ‚îî‚îÄ‚îÄ templates/nginx.conf.j2
‚îú‚îÄ‚îÄ mysql/
‚îÇ   ‚îî‚îÄ‚îÄ tasks/main.yml
‚îî‚îÄ‚îÄ app/
    ‚îî‚îÄ‚îÄ tasks/main.yml
```

### 3.3 Modules Ansible Courants

| Module | But | Exemple |
|--------|-----|---------|
| `apt` / `yum` | Installer packages | `apt: name=nginx state=present` |
| `systemd` | G√©rer services | `systemd: name=nginx state=started` |
| `copy` | Copier fichiers | `copy: src=app.conf dest=/etc/app.conf` |
| `template` | D√©ployer fichiers Jinja2 | `template: src=nginx.j2 dest=/etc/nginx.conf` |
| `command` / `shell` | Lancer commandes | `shell: systemctl reload nginx` |
| `file` | Cr√©er/supprimer fichiers | `file: path=/tmp/test state=absent` |
| `git` | Cloner repos | `git: repo=https://github.com/app.git` |
| `docker_container` | G√©rer conteneurs | `docker_container: name=web image=nginx` |
| `uri` | Tester endpoints HTTP | `uri: url=http://localhost/health status_code=200` |
| `debug` | Afficher messages | `debug: msg="Server {{ inventory_hostname }} ready"` |

### 3.4 Playbook Complet : Installer Nginx + D√©ployer Page

```yaml
---
- name: Configure web servers with Nginx
  hosts: webservers
  become: yes
  gather_facts: yes

  vars:
    nginx_port: 80
    app_dir: /var/www/devcloud

  tasks:
    # Mise √† jour syst√®me
    - name: Update APT cache
      apt:
        update_cache: yes
        cache_valid_time: 3600

    # Installer Nginx
    - name: Install Nginx
      apt:
        name: nginx
        state: present

    # Cr√©er r√©pertoire application
    - name: Create app directory
      file:
        path: "{{ app_dir }}"
        state: directory
        mode: '0755'

    # D√©ployer page HTML
    - name: Deploy index.html
      copy:
        content: |
          <!DOCTYPE html>
          <html>
          <head><title>DevCloud - Module 3</title></head>
          <body>
            <h1>Infrastructure as Code en action!</h1>
            <p>Serveur: {{ ansible_hostname }}</p>
            <p>IP: {{ ansible_default_ipv4.address }}</p>
          </body>
          </html>
        dest: "{{ app_dir }}/index.html"
      notify: restart nginx

    # D√©ployer configuration Nginx (template Jinja2)
    - name: Deploy Nginx config
      template:
        src: nginx.conf.j2
        dest: /etc/nginx/sites-available/devcloud
      notify: restart nginx

    # Activer site
    - name: Enable devcloud site
      file:
        src: /etc/nginx/sites-available/devcloud
        dest: /etc/nginx/sites-enabled/devcloud
        state: link
        force: yes
      notify: restart nginx

    # D√©marrer Nginx
    - name: Start Nginx
      systemd:
        name: nginx
        state: started
        enabled: yes

    # Health check
    - name: Wait for Nginx
      wait_for:
        port: "{{ nginx_port }}"
        delay: 2

    - name: Test Nginx response
      uri:
        url: "http://localhost:{{ nginx_port }}/index.html"
        status_code: 200
      register: http_test

    - name: Success message
      debug:
        msg: "‚úì Nginx is running (status {{ http_test.status }})"

  handlers:
    - name: restart nginx
      systemd:
        name: nginx
        state: restarted
```

### 3.5 Template Jinja2 : nginx.conf.j2

```jinja2
server {
    listen {{ nginx_port }} default_server;
    server_name _;
    
    root {{ app_dir }};
    index index.html;
    
    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    # Health check endpoint
    location /health {
        access_log off;
        return 200 "healthy\n";
    }
    
    # Logging
    access_log /var/log/nginx/devcloud_access.log;
    error_log /var/log/nginx/devcloud_error.log;
}
```

### 3.6 Int√©gration Terraform ‚Üí Ansible

**Probl√®me :** Comment passer les IPs des instances Terraform √† Ansible ?

**Solution :** Ansible Dynamic Inventory

**Script : terraform-to-ansible.sh**
```bash
#!/bin/bash
# G√©n√©rer hosts.ini depuis Terraform outputs

terraform output -json instance_ips | jq -r 'to_entries[] | "\(.key) ansible_host=\(.value)"' > hosts.ini

# Ajouter variables
cat >> hosts.ini << 'EOF'

[webservers:vars]
ansible_ssh_private_key_file=~/.ssh/id_rsa
ansible_user=ubuntu
EOF

# Tester connectivit√©
ansible -i hosts.ini all -m ping

# Ex√©cuter playbook
ansible-playbook -i hosts.ini playbook.yml
```

---

## CHAPITRE 4 : Architecture Cloud R√©seau

### 4.1 VPC : Votre R√©seau Priv√©

**Virtual Private Cloud (VPC)** = Un r√©seau priv√© que vous louez dans le cloud.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     AWS (R√©gion: eu-west-3)         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  VPC: 10.0.0.0/16             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Subnet Public           ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ 10.0.1.0/24             ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ [EC2-1] [EC2-2]         ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ       [Internet Gateway]      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ               ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                  ‚îÇ                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
              [INTERNET]
```

**CIDR Notation :**
- `10.0.0.0/16` = R√©seau de 65,536 IPs (10.0.0.0 √† 10.0.255.255)
- `10.0.1.0/24` = Subnet de 256 IPs (10.0.1.0 √† 10.0.1.255)
- R√©serv√©es : `.0` (r√©seau) et `.255` (broadcast)
- Utilisables : `.1` √† `.254`

### 4.2 Subnets : Diviser le R√©seau

**Subnet Public :** Instances ont une IP publique, peuvent recevoir Internet.

```hcl
resource "aws_subnet" "public" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.1.0/24"
  map_public_ip_on_launch = true  # IP publique automatique
}
```

**Subnet Priv√© :** Instances n'ont PAS d'IP publique, ne re√ßoivent pas Internet directement.

```hcl
resource "aws_subnet" "private" {
  vpc_id     = aws_vpc.main.id
  cidr_block = "10.0.2.0/24"
  # Pas de map_public_ip_on_launch
}
```

**Pourquoi priv√© ?** Pour prot√©ger les bases de donn√©es. Elles ne doivent pas √™tre accessibles directement depuis Internet.

### 4.3 Internet Gateway (IGW)

Permet au trafic de circuler entre VPC et Internet.

```hcl
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
}
```

### 4.4 NAT Gateway (Pour Subnets Priv√©s)

Permet aux instances **priv√©es** de sortir sur Internet (pour t√©l√©charger packages), mais pas de recevoir connexions entrantes.

```hcl
# NAT Gateway (co√ªts !!)
resource "aws_nat_gateway" "main" {
  allocation_id = aws_eip.nat.id
  subnet_id     = aws_subnet.public.id  # Doit √™tre en subnet public
}

# Route table priv√©e
resource "aws_route_table" "private" {
  vpc_id = aws_vpc.main.id
  
  route {
    cidr_block     = "0.0.0.0/0"
    nat_gateway_id = aws_nat_gateway.main.id
  }
}
```

### 4.5 Security Groups : Pare-feu Instance

Contr√¥le quel trafic est autoris√© **entrant** et **sortant**.

```hcl
resource "aws_security_group" "web" {
  vpc_id = aws_vpc.main.id
  
  # ENTRANT
  ingress {
    from_port   = 22    # Port SSH
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]  # Depuis anywhere
  }
  
  ingress {
    from_port   = 80    # Port HTTP
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  # SORTANT (tout autoris√© par d√©faut)
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
```

### 4.6 Load Balancer (ALB)

Distribue le trafic entre plusieurs instances.

```hcl
resource "aws_lb" "main" {
  internal           = false
  load_balancer_type = "application"
  subnets            = [aws_subnet.public.id]
  
  enable_deletion_protection = false
}

# Target group (instances √† equilibrer)
resource "aws_lb_target_group" "web" {
  port     = 80
  protocol = "HTTP"
  vpc_id   = aws_vpc.main.id
  
  health_check {
    healthy_threshold   = 2
    unhealthy_threshold = 2
    timeout             = 3
    interval            = 30
    path                = "/health"
    matcher             = "200"
  }
}

# Listener (re√ßoit trafic)
resource "aws_lb_listener" "main" {
  load_balancer_arn = aws_lb.main.arn
  port              = 80
  protocol          = "HTTP"
  
  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.web.arn
  }
}
```

### 4.7 Auto-Scaling Group (ASG)

Cr√©e/d√©truit instances automatiquement selon la charge CPU.

```hcl
resource "aws_launch_template" "web" {
  image_id      = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.micro"
  
  iam_instance_profile {
    name = aws_iam_instance_profile.web.name
  }
}

resource "aws_autoscaling_group" "web" {
  launch_template {
    id      = aws_launch_template.web.id
    version = "$Latest"
  }
  
  min_size         = 2
  max_size         = 10
  desired_capacity = 3
  
  vpc_zone_identifier = [aws_subnet.public.id]
  target_group_arns   = [aws_lb_target_group.web.arn]
  
  health_check_type         = "ELB"
  health_check_grace_period = 300
}

# Scaling policy : ajouter instance si CPU > 70%
resource "aws_autoscaling_policy" "scale_up" {
  autoscaling_group_name = aws_autoscaling_group.web.name
  adjustment_type        = "ChangeInCapacity"
  scaling_adjustment     = 1
  cooldown               = 60
}
```

---

## CHAPITRE 5 : Haute Disponibilit√© & R√©silience

### 5.1 RTO & RPO : D√©finitions Critiques

| Terme | Signification | Exemple |
|-------|--------------|---------|
| **RTO** | Recovery Time Objective | "Combien de temps avant la services est r√©tabli?" |
| **RPO** | Recovery Point Objective | "Combien de donn√©es peux-je perdre?" |

**Exemples Chiffr√©s :**

| Service | RTO | RPO | Strat√©gie |
|---------|-----|-----|-----------|
| **Blog personnel** | 1 jour | 1 jour | Backup quotidien |
| **Site e-commerce** | 1 heure | 15 min | R√©plication SQL toutes les 15 min |
| **Banque** | < 1 minute | 0 (temps r√©el) | R√©plication synchrone, multi-datacenter |
| **H√¥pital** | < 1 minute | < 1 seconde | Infrastructure ultra-redondante |

### 5.2 Multi-AZ : Redondance G√©ographique

**AZ = Availability Zone** = Datacenter dans une r√©gion.

**AWS eu-west-3 (Paris) a 3 AZ :**
```
Paris (eu-west-3)
‚îú‚îÄ‚îÄ eu-west-3a (Nord)
‚îú‚îÄ‚îÄ eu-west-3b (Centre)
‚îî‚îÄ‚îÄ eu-west-3c (Sud)

Distance entre AZ : ~20km (m√™me si l'une br√ªle, l'autre est OK)
```

**Architecture Simple-Zone (Risqu√©) :**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    eu-west-3a (Single AZ)        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ VPC: 10.0.0.0/16         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ [EC2-1] [EC2-2]          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ [RDS Database]           ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Probl√®me : Un seul incendie = tout down
```

**Architecture Multi-AZ (Recommand√©) :**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           AWS (R√©gion: eu-west-3)                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ  AZ: eu-west-3a   ‚îÇ        ‚îÇ  AZ: eu-west-3b   ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ [EC2-1]           ‚îÇ        ‚îÇ [EC2-2]           ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ [10.0.1.0/24]     ‚îÇ        ‚îÇ [10.0.2.0/24]     ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ           ‚îÇ                            ‚îÇ                     ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îÇ                 [Load Balancer]                              ‚îÇ
‚îÇ                           ‚îÇ                                  ‚îÇ
‚îÇ           [RDS Multi-AZ Database]  (R√©plication)             ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Avantage : Un AZ br√ªle ? L'autre prend le relais (failover auto)
```

### 5.3 Failover Automatique

**Health Check :** Le load balancer teste r√©guli√®rement les instances.

```
Load Balancer
    ‚îÇ
    ‚îú‚îÄ‚Üí ping EC2-1 (port 80)   ‚úì Sain
    ‚îú‚îÄ‚Üí ping EC2-2 (port 80)   ‚úì Sain
    ‚îî‚îÄ‚Üí Toutes routes vers EC2-1 et EC2-2

Si EC2-1 crash :
    ‚îÇ
    ‚îú‚îÄ‚Üí ping EC2-1 (port 80)   ‚úó Pas de r√©ponse
    ‚îî‚îÄ‚Üí Tout trafic ‚Üí EC2-2 (failover automatique)

Si EC2-1 revient :
    ‚îú‚îÄ‚Üí ping EC2-1 (port 80)   ‚úì Sain
    ‚îî‚îÄ‚Üí R√©partition restored
```

**Code Terraform Multi-AZ :**
```hcl
variable "availability_zones" {
  default = ["eu-west-3a", "eu-west-3b"]
}

# Cr√©er subnet pour chaque AZ
resource "aws_subnet" "public" {
  for_each              = toset(var.availability_zones)
  vpc_id                = aws_vpc.main.id
  cidr_block            = "10.0.${index(var.availability_zones, each.value) + 1}.0/24"
  availability_zone     = each.value
  map_public_ip_on_launch = true
}

# Cr√©er instance pour chaque AZ
resource "aws_instance" "web" {
  for_each           = toset(var.availability_zones)
  ami                = "ami-0c55b159cbfafe1f0"
  instance_type      = "t3.micro"
  subnet_id          = aws_subnet.public[each.value].id
  security_groups    = [aws_security_group.web.id]
  
  tags = { Name = "web-${each.value}" }
}
```

---

## CAS D'√âTUDE : TechNova Phase 2

### Contexte Sc√©nario

**TechNova**, la startup SaaS qu'on accompagne depuis Module 1, valide sa strat√©gie cloud (Module 2). Ils passent maintenant en **production**.

**Probl√®me :** Le stagiaire a effac√© manuellement le serveur de production hier par erreur. Oups.

**Mission :** Cr√©er une infrastructure **codifi√©e en Terraform** pour pouvoir la red√©ployer en moins de 5 minutes en cas de d√©sastre.

### Architecture Simple (TP3.1)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TechNova - Phase 2 (Production Basique)   ‚îÇ
‚îÇ                                            ‚îÇ
‚îÇ  VPC: 10.0.0.0/16                          ‚îÇ
‚îÇ  ‚îú‚îÄ Subnet Public: 10.0.1.0/24             ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ [Web Server 1] (3.121.45.67)       ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ [Web Server 2] (3.121.45.68)       ‚îÇ
‚îÇ  ‚îÇ                                         ‚îÇ
‚îÇ  ‚îú‚îÄ Internet Gateway                       ‚îÇ
‚îÇ  ‚îî‚îÄ Security Group                         ‚îÇ
‚îÇ      ‚îú‚îÄ SSH (port 22)                      ‚îÇ
‚îÇ      ‚îú‚îÄ HTTP (port 80)                     ‚îÇ
‚îÇ      ‚îî‚îÄ HTTPS (port 443)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Architecture Haute Disponibilit√© (Aller plus loin)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     TechNova - Phase 2 (Production Avanc√©e)              ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Multi-AZ Failover                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  AZ: eu-west-3a ‚îÇ    ‚îÇ  AZ: eu-west-3b ‚îÇ        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  [Web-1]        ‚îÇ    ‚îÇ  [Web-2]        ‚îÇ        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  [10.0.1.0/24]  ‚îÇ    ‚îÇ  [10.0.2.0/24]  ‚îÇ        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ           ‚îÇ                      ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         [Load Balancer (ALB)]                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         Health Check (Health/30s)                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    [RDS Database - Multi-AZ Replication]           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  RTO: < 1 minute (failover automatique)                  ‚îÇ
‚îÇ  RPO: 0 secondes (r√©plication synchrone)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Points Cl√©s pour TechNova

1. **Reproductibilit√©** : Terraform permet de recr√©er l'infra en 5 minutes.
2. **Versionning** : Git trace qui a chang√© quoi et quand.
3. **Scaling** : Avec Auto-Scaling Group, g√©rer 1000 utilisateurs ou 1 million, c'est pareil.
4. **Co√ªts** : Destroy apr√®s TP = z√©ro co√ªts.

---

## Glossaire & Ressources

### Termes Techniques

| Terme | D√©finition |
|-------|-----------|
| **HCL** | HashiCorp Configuration Language (langage Terraform) |
| **Provider** | Plugin Terraform pour une plateforme (AWS, Azure, etc.) |
| **Resource** | Une entit√© cloud (EC2, VPC, subnet, etc.) |
| **State** | Fichier `.tfstate` (m√©moire Terraform) |
| **Idempotent** | Ex√©cuter 2 fois = m√™me r√©sultat |
| **Drift** | Changements manuels non autoris√©s |
| **VPC** | Virtual Private Cloud (r√©seau priv√©) |
| **Subnet** | Segment de VPC avec son CIDR |
| **CIDR** | Notation pour notation plages IP (10.0.0.0/16) |
| **Security Group** | Pare-feu au niveau instance |
| **NAT Gateway** | Sortie anonyme pour subnets priv√©s |
| **ALB** | Application Load Balancer |
| **ASG** | Auto-Scaling Group |
| **Playbook** | Fichier YAML Ansible d√©crivant t√¢ches |
| **Inventory** | Liste des serveurs Ansible |
| **Handler** | T√¢che sp√©ciale qui s'ex√©cute si notifi√©e |
| **Template** | Fichier dynamique (Jinja2) |
| **RTO** | Recovery Time Objective (temps pour r√©tablir) |
| **RPO** | Recovery Point Objective (donn√©es perdues max) |
| **Multi-AZ** | Redondance sur plusieurs datacenters |
| **Health Check** | V√©rification r√©guli√®re de l'√©tat des services |

### Documentation Officielle

- **Terraform Registry :** https://registry.terraform.io/
- **Terraform AWS Provider :** https://registry.terraform.io/providers/hashicorp/aws/latest
- **Ansible Docs :** https://docs.ansible.com/
- **AWS VPC Documentation :** https://docs.aws.amazon.com/vpc/
- **Terraform Best Practices :** https://www.terraform.io/docs/cloud/guides/recommended-practices

### Tutoriels Recommand√©s

- **Terraform in 100 Seconds** (FreeCodeCamp YouTube)
- **Ansible Getting Started** (ansible.com docs)
- **AWS for Beginners** (various CloudAcademy courses)

### Outils Pratiques

```bash
# Formater code Terraform
terraform fmt

# Linter Terraform
tflint

# Ansible linter
ansible-lint playbook.yml

# Check Ansible syntax
ansible-playbook playbook.yml --syntax-check
```

---

## ‚úÖ Checklist : √ätes-vous pr√™t pour les TPs ?

Avant de commencer les travaux pratiques, v√©rifiez que vous comprenez :

- [ ] Diff√©rence entre approche d√©clarative (Terraform) et imp√©rative (Ansible)
- [ ] Les 4 √©tapes du workflow Terraform (init, plan, apply, destroy)
- [ ] Pourquoi le fichier `.tfstate` est critique
- [ ] Concept d'idempotence (pourquoi terraform apply 2 fois = m√™me r√©sultat)
- [ ] Configuration Drift et comment le d√©tecter
- [ ] Structure VPC : VPC ‚Üí Subnets ‚Üí Internet Gateway ‚Üí Routage
- [ ] Security Groups : ingress vs egress
- [ ] Ansible : inventory, playbooks, handlers, templates
- [ ] Comment passer les outputs Terraform √† Ansible
- [ ] Multi-AZ et failover automatique (concept, pas obligatoire pour TP)

**Si vous cochez 8+ points : Vous √™tes pr√™t ! üöÄ**


# SUPPORT DE TRAVAUX PRATIQUES (TP3)

**Dur√©e :** 3 heures  
**Outils :** Terraform, Ansible, AWS CLI, SSH  
**Sc√©nario :** TechNova ‚Äì Phase 2 (Red√©ploiement d'urgence)

---

## TABLE DES MATI√àRES

- [Pr√©ambule & Sc√©nario](#preambule)
- [Pr√©-requis](#prequisite)
- [TP3.1 : Provisionning Infrastructure avec Terraform (1.5h)](#tp31)
- [TP3.2 : Configuration avec Ansible (1.5h)](#tp32)
- [√âvaluation & Rubrics](#evaluation)
- [D√©pannage Rapide](#depannage)

---

## PR√âAMBULE & SC√âNARIO

### Contexte

**TechNova** a valid√© sa strat√©gie cloud (Module 2). Ils passent maintenant en **production avec deux serveurs web**.

**Hier :** Le stagiaire a cliqu√© sur "Terminer instance" par erreur √† 14h47.

**Aujourd'hui :** Vous devez red√©ployer l'infrastructure **identique** en moins de 5 minutes. Comment ? Avec du code.

### Objectifs P√©dagogiques

√Ä la fin des TPs, vous devrez √™tre capable de :

1. ‚úÖ √âcrire un plan Terraform complet (provider, ressources, outputs)
2. ‚úÖ Provisionner une infrastructure cloud (VPC, Subnet, IGW, EC2, SG)
3. ‚úÖ Appliquer le workflow Terraform (init, plan, apply, destroy)
4. ‚úÖ G√©n√©rer un inventaire Ansible depuis Terraform outputs
5. ‚úÖ Configurer des serveurs avec Ansible playbooks
6. ‚úÖ D√©ployer une application avec templates Jinja2
7. ‚úÖ Valider l'infrastructure (health checks, tests HTTP)
8. ‚úÖ Nettoyer compl√®tement les ressources (co√ªts)

### Timing Pr√©vu

```
00:00-00:15 ‚Üí Setup & validations
00:15-01:15 ‚Üí TP3.1 Terraform (Cr√©er infra)
01:15-01:30 ‚Üí Pause
01:30-03:00 ‚Üí TP3.2 Ansible (Configurer)
```

---

## ‚úÖ PR√â-REQUIS

Avant de commencer, v√©rifiez que vous avez :

### Logiciels √† Installer

```bash
# 1. V√©rifier Terraform
terraform version
# Output attendu : Terraform v1.5+ (au minimum v1.0)

# 2. V√©rifier Ansible
ansible --version
# Output attendu : ansible 2.9+

# 3. V√©rifier AWS CLI
aws --version
# Output attendu : aws-cli/2.x

# 4. V√©rifier Git
git --version
# Output attendu : git version 2.x+

# 5. V√©rifier cl√© SSH
ls ~/.ssh/id_rsa.pub
# Output attendu : afficher le chemin (ex: /home/user/.ssh/id_rsa.pub)
```

### Compte AWS

- [ ] Compte AWS avec cr√©dits Free Tier disponibles
- [ ] Credentials configur√©es : `aws configure` (ou variables d'env)
- [ ] R√©gion par d√©faut : `eu-west-3` (Paris)

### Dossier de Travail

```bash
# Cr√©er dossier projet
mkdir -p ~/techNova-iac/terraform ~/techNova-iac/ansible
cd ~/techNova-iac

# Arborescence attendue
techNova-iac/
‚îú‚îÄ‚îÄ terraform/
‚îÇ   ‚îú‚îÄ‚îÄ main.tf              # Configuration provider
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf         # Variables
‚îÇ   ‚îú‚îÄ‚îÄ vpc.tf               # R√©seau
‚îÇ   ‚îú‚îÄ‚îÄ security.tf          # S√©curit√©
‚îÇ   ‚îú‚îÄ‚îÄ instances.tf         # EC2
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf           # R√©sultats
‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars     # Valeurs
‚îú‚îÄ‚îÄ ansible/
‚îÇ   ‚îú‚îÄ‚îÄ playbook.yml         # Playbook principal
‚îÇ   ‚îú‚îÄ‚îÄ hosts.ini            # Inventaire (g√©n√©r√©)
‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf.j2        # Template
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ terraform-to-ansible.sh  # Script int√©gration
    ‚îî‚îÄ‚îÄ cleanup.sh               # Nettoyage
```

---

## TP3.1 : Provisionning Infrastructure avec Terraform

**Dur√©e :** 1 heure 30 minutes  
**Livrable :** Infrastructure AWS fonctionnelle + captures d'√©cran

### Objectifs TP3.1

- [ ] Initialiser projet Terraform
- [ ] Configurer provider AWS
- [ ] Cr√©er VPC + Subnet public + Internet Gateway
- [ ] Cr√©er Security Group (SSH + HTTP)
- [ ] Lancer 2 instances EC2 (t3.micro)
- [ ] G√©n√©rer outputs (IPs publiques)
- [ ] Valider avec terraform plan
- [ ] Appliquer avec terraform apply
- [ ] Tester SSH vers une instance
- [ ] Nettoyer avec terraform destroy

### √âtape 1 : Initialiser le Projet (5 min)

```bash
cd ~/techNova-iac/terraform

# 1a. Cr√©er fichier main.tf
cat > main.tf << 'EOF'
terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = "eu-west-3"  # Paris
  
  default_tags {
    tags = {
      Project     = "TechNova-Phase2"
      Environment = "dev"
      ManagedBy   = "Terraform"
    }
  }
}
EOF

# 1b. Initialiser Terraform
terraform init

# Output attendu:
# Initializing the backend...
# Downloading aws v5.x.x...
# Terraform has been successfully configured!
```

**Checkpoint 1 ‚úì**
```bash
# V√©rifier que tout est OK
ls -la
# V√©rifier pr√©sence de .terraform/
```

### √âtape 2 : Configurer Variables (5 min)

```bash
# 2a. Cr√©er fichier variables.tf
cat > variables.tf << 'EOF'
variable "vpc_cidr" {
  type        = string
  default     = "10.0.0.0/16"
  description = "CIDR block du VPC"
}

variable "instance_type" {
  type        = string
  default     = "t3.micro"
  description = "Type instance EC2 (free tier)"
}

variable "instance_count" {
  type        = number
  default     = 2
  description = "Nombre d'instances √† cr√©er"
  
  validation {
    condition     = var.instance_count > 0 && var.instance_count <= 5
    error_message = "Entre 1 et 5 instances."
  }
}
EOF

# 2b. Cr√©er fichier terraform.tfvars (surcharge valeurs)
cat > terraform.tfvars << 'EOF'
vpc_cidr       = "10.0.0.0/16"
instance_type  = "t3.micro"
instance_count = 2
EOF
```

### √âtape 3 : Cr√©er R√©seau VPC (15 min)

```bash
# 3a. Cr√©er fichier vpc.tf
cat > vpc.tf << 'EOF'
# ==================== VPC ====================

resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = { Name = "vpc-technova" }
}

# ==================== SUBNET PUBLIC ====================

resource "aws_subnet" "public" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.1.0/24"
  availability_zone       = "eu-west-3a"
  map_public_ip_on_launch = true

  tags = { Name = "subnet-public-technova" }
}

# ==================== INTERNET GATEWAY ====================

resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id

  tags = { Name = "igw-technova" }
}

# ==================== ROUTE TABLE ====================

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block      = "0.0.0.0/0"
    gateway_id      = aws_internet_gateway.main.id
  }

  tags = { Name = "rt-public-technova" }

  depends_on = [aws_internet_gateway.main]
}

# ==================== ROUTE TABLE ASSOCIATION ====================

resource "aws_route_table_association" "public" {
  subnet_id      = aws_subnet.public.id
  route_table_id = aws_route_table.public.id
}
EOF

# 3b. Valider syntaxe
terraform validate

# Output attendu : Success! The configuration is valid.
```

**Checkpoint 2 ‚úì**
```bash
terraform plan | grep -E "(add|change|destroy)"
# V√©rifier : "Plan: X to add, 0 to change, 0 to destroy"
```

### √âtape 4 : Cr√©er S√©curit√© & Cl√© SSH (10 min)

```bash
# 4a. Cr√©er fichier security.tf
cat > security.tf << 'EOF'
# ==================== SECURITY GROUP ====================

resource "aws_security_group" "web" {
  name        = "sg-web-technova"
  description = "Security group pour serveurs web"
  vpc_id      = aws_vpc.main.id

  # ========== INBOUND ==========

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
    description = "SSH access"
  }

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
    description = "HTTP access"
  }

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
    description = "HTTPS access"
  }

  # ========== OUTBOUND ==========

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
    description = "Allow all outbound"
  }

  tags = { Name = "sg-web-technova" }
}

# ==================== SSH KEY PAIR ====================

resource "aws_key_pair" "deployer" {
  key_name   = "deployer-technova"
  public_key = file("~/.ssh/id_rsa.pub")

  tags = { Name = "deployer-key" }
}
EOF

# 4b. Valider
terraform validate
```

**Checkpoint 3 ‚úì**
```bash
terraform plan | grep "aws_security_group\|aws_key_pair"
# V√©rifier pr√©sence dans plan
```

### √âtape 5 : Lancer Instances EC2 (10 min)

```bash
# 5a. Cr√©er fichier instances.tf
cat > instances.tf << 'EOF'
# ==================== DATA : Trouver AMI Ubuntu ====================

data "aws_ami" "ubuntu" {
  most_recent = true
  owners      = ["099720109477"]  # Canonical

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }
}

# ==================== EC2 INSTANCES ====================

resource "aws_instance" "web" {
  count              = var.instance_count
  ami                = data.aws_ami.ubuntu.id
  instance_type      = var.instance_type
  key_name           = aws_key_pair.deployer.key_name
  subnet_id          = aws_subnet.public.id
  security_groups    = [aws_security_group.web.id]
  monitoring         = true

  root_block_device {
    volume_type           = "gp3"
    volume_size           = 20
    delete_on_termination = true
    encrypted             = true
  }

  tags = {
    Name = "web-technova-${count.index + 1}"
  }

  depends_on = [aws_internet_gateway.main]

  lifecycle {
    create_before_destroy = true
  }
}
EOF

# 5b. Valider
terraform validate
```

### √âtape 6 : Configurer Outputs (10 min)

```bash
# 6a. Cr√©er fichier outputs.tf
cat > outputs.tf << 'EOF'
# ==================== VPC OUTPUTS ====================

output "vpc_id" {
  description = "ID du VPC"
  value       = aws_vpc.main.id
}

output "subnet_id" {
  description = "ID du subnet public"
  value       = aws_subnet.public.id
}

# ==================== INSTANCE OUTPUTS ====================

output "instance_ids" {
  description = "IDs des instances EC2"
  value       = aws_instance.web[*].id
}

output "instance_ips_public" {
  description = "IPs publiques (SSH/HTTP)"
  value       = aws_instance.web[*].public_ip
}

output "instance_ips_private" {
  description = "IPs priv√©es"
  value       = aws_instance.web[*].private_ip
}

# ==================== ANSIBLE OUTPUTS ====================

output "instance_ips" {
  description = "IPs publiques format√©es pour Ansible"
  value = {
    for i, instance in aws_instance.web :
    instance.tags["Name"] => instance.public_ip
  }
}

# Inventaire Ansible ready-to-use
output "ansible_inventory" {
  description = "Inventaire Ansible (copy-paste)"
  value = "[webservers]\n${join("\n", [
    for i, instance in aws_instance.web :
    "${instance.tags["Name"]} ansible_host=${instance.public_ip} ansible_user=ubuntu"
  ])}\n\n[webservers:vars]\nansible_ssh_private_key_file=~/.ssh/id_rsa"
}

# ==================== SUMMARY ====================

output "deployment_summary" {
  description = "R√©sum√© du d√©ploiement"
  value = {
    vpc_cidr       = aws_vpc.main.cidr_block
    subnet_cidr    = aws_subnet.public.cidr_block
    instances_count = var.instance_count
    instance_type  = var.instance_type
  }
}
EOF

# 6b. Valider
terraform validate

# Output attendu : Success!
```

**Checkpoint 4 ‚úì**
```bash
terraform validate
# V√©rifier output
```

### √âtape 7 : Terraform Plan (10 min)

```bash
# 7a. V√©rifier le plan AVANT d'appliquer
terraform plan -out=tfplan

# Output attendu ressemble √† :
# Plan: 8 to add, 0 to change, 0 to destroy.
#
# aws_vpc.main will be created
# aws_subnet.public will be created
# aws_internet_gateway.main will be created
# ... (autres ressources)

# Nombre exact peut varier, mais autour de 8 ressources
```

**IMPORTANT :** Lisez le plan enti√®rement ! V√©rifiez :
- [ ] VPC CIDR : 10.0.0.0/16
- [ ] Subnet CIDR : 10.0.1.0/24
- [ ] 2 instances EC2 (count = 2)
- [ ] Security Group avec SSH (22) et HTTP (80)
- [ ] Aucune ressource ne sera supprim√©e (destroy = 0)

### √âtape 8 : Terraform Apply (15 min)

```bash
# 8a. APPLIQUER LE PLAN (cr√©ation r√©elle)
terraform apply tfplan

# Output attendu :
# aws_vpc.main: Creating...
# aws_vpc.main: Creation complete after 2s [id=vpc-0123456789]
# aws_internet_gateway.main: Creating...
# ...
# Apply complete! Resources: 8 added, 0 changed, 0 destroyed.

# ‚è±Ô∏è Temps attendu : 3-5 minutes pour tout
```

**Checkpoint 5 ‚úì**
```bash
# V√©rifier que tout est cr√©√©
terraform state list | wc -l
# Devrait afficher ~8 ressources
```

### √âtape 9 : Afficher Outputs (5 min)

```bash
# 9a. Afficher outputs (IPs publiques)
terraform output instance_ips

# Output attendu :
# instance_ips = {
#   "web-technova-1" = "3.121.45.67"
#   "web-technova-2" = "3.121.45.68"
# }

# 9b. Afficher inventaire Ansible (utile pour TP3.2)
terraform output -raw ansible_inventory

# Output attendu :
# [webservers]
# web-technova-1 ansible_host=3.121.45.67 ansible_user=ubuntu
# web-technova-2 ansible_host=3.121.45.68 ansible_user=ubuntu
#
# [webservers:vars]
# ansible_ssh_private_key_file=~/.ssh/id_rsa

# 9c. Sauvegarder dans fichier
terraform output -raw ansible_inventory > ../ansible/hosts.ini
```

**Checkpoint 6 ‚úì**
```bash
cat ../ansible/hosts.ini
# V√©rifier pr√©sence des IPs
```

### √âtape 10 : Tester SSH (10 min)

```bash
# 10a. R√©cup√©rer une IP
IP=$(terraform output -json instance_ips | jq -r 'to_entries[0].value')
echo "IP de test : $IP"

# 10b. Attendre que l'instance soit pr√™te
echo "‚è≥ Attente 30s pour que l'instance d√©marre..."
sleep 30

# 10c. Tester SSH
ssh -i ~/.ssh/id_rsa -o StrictHostKeyChecking=no ubuntu@$IP "whoami"

# Output attendu : ubuntu

# 10d. Tester depuis l'instance
ssh -i ~/.ssh/id_rsa ubuntu@$IP "uname -a"

# Output attendu : Linux web-technova-1 5.15.0-... Ubuntu...

# 10e. Afficher IPs publiques
echo "‚úì Instances d√©ploy√©es avec succ√®s !"
echo ""
echo "IPs publiques :"
terraform output instance_ips
```

**Checkpoint 7 ‚úì**
```bash
# Vous devriez pouvoir SSH sans erreurs
```

### √âtape 11 : Capturer & Documenter (10 min)

```bash
# 11a. Capture terraform plan
terraform plan > ~/plan_screenshot.txt

# 11b. Capture terraform state
terraform show > ~/state_screenshot.txt

# 11c. Capture outputs
terraform output > ~/outputs_screenshot.txt

# 11d. Cr√©er fichier README
cat > README.md << 'EOF'
# TechNova Phase 2 - Infrastructure as Code

## D√©ploiement Terraform r√©ussi

**Date :** $(date)
**Ressources cr√©√©es :** 8

### Instances EC2
- Instance 1 : web-technova-1
- Instance 2 : web-technova-2

### VPC
- ID VPC : $(terraform output -raw vpc_id)
- CIDR : 10.0.0.0/16

### IPs Publiques
$(terraform output instance_ips)

## Prochaine √©tape
Lancer TP3.2 (Ansible) pour configurer les serveurs.
EOF

cat README.md
```

### ‚úÖ Livrables TP3.1

Avant de passer √† TP3.2, assurez-vous d'avoir :

- [ ] Fichiers Terraform cr√©√©s (main.tf, variables.tf, vpc.tf, security.tf, instances.tf, outputs.tf)
- [ ] Ex√©cution sans erreurs : `terraform validate` ‚úì
- [ ] Plan g√©n√©r√© : `terraform plan` affiche "Plan: 8 to add..."
- [ ] Infrastructure cr√©√©e : `terraform apply` r√©ussi
- [ ] IPs publiques obtenues et affich√©es
- [ ] SSH fonctionnel vers au moins une instance
- [ ] Inventaire Ansible g√©n√©r√© (hosts.ini)
- [ ] Captures d'√©cran ou fichiers logs

---

## TP3.2 : Configuration avec Ansible (1.5h) 

**Dur√©e :** 1 heure 30 minutes  
**Pr√©requisite :** TP3.1 compl√©t√©  
**Livrable :** Serveurs web fonctionnels avec Nginx

### Objectifs TP3.2

- [ ] G√©n√©rer inventaire Ansible depuis Terraform
- [ ] Tester connectivit√© Ansible (ping)
- [ ] √âcrire playbook Ansible (installer Nginx)
- [ ] Cr√©er template Jinja2 (configuration Nginx)
- [ ] D√©ployer page HTML dynamique
- [ ] Configurer handlers (restart Nginx)
- [ ] Lancer playbook et v√©rifier
- [ ] Acc√©der √† pages depuis navigateur
- [ ] Valider health checks

### √âtape 1 : G√©n√©rer Inventaire Ansible (5 min)

```bash
cd ~/techNova-iac/ansible

# 1a. G√©n√©rer hosts.ini depuis Terraform outputs
terraform output -raw ansible_inventory > hosts.ini

# 1b. V√©rifier contenu
cat hosts.ini

# Output attendu :
# [webservers]
# web-technova-1 ansible_host=3.121.45.67 ansible_user=ubuntu
# web-technova-2 ansible_host=3.121.45.68 ansible_user=ubuntu
#
# [webservers:vars]
# ansible_ssh_private_key_file=~/.ssh/id_rsa
```

**Checkpoint 1 ‚úì**
```bash
wc -l hosts.ini
# Devrait avoir au moins 5 lignes
```

### √âtape 2 : Tester Connectivit√© Ansible (5 min)

```bash
# 2a. V√©rifier que Ansible peut atteindre les instances
ansible -i hosts.ini all -m ping

# Output attendu :
# web-technova-1 | SUCCESS => {
#     "ping": "pong"
# }
# web-technova-2 | SUCCESS => {
#     "ping": "pong"
# }

# 2b. Si erreur "Unreachable" :
# ‚Üí Attendre quelques secondes (instances en d√©marrage)
# ‚Üí V√©rifier Security Group (port 22 ouvert)
# ‚Üí V√©rifier cl√© SSH : ls -la ~/.ssh/id_rsa

sleep 30
ansible -i hosts.ini all -m ping
```

**Checkpoint 2 ‚úì**
```bash
# Devrait afficher SUCCESS sur les 2 instances
```

### √âtape 3 : Cr√©er Playbook Ansible (20 min)

```bash
# 3a. Cr√©er playbook.yml
cat > playbook.yml << 'EOF'
---
- name: Configure web servers with Nginx
  hosts: webservers
  become: yes
  gather_facts: yes

  vars:
    nginx_port: 80
    app_dir: /var/www/devcloud
    app_user: www-data

  pre_tasks:
    - name: Display deployment info
      debug:
        msg: |
          D√©ploiement vers {{ inventory_hostname }}
          IP : {{ ansible_default_ipv4.address }}
          OS : {{ ansible_distribution }} {{ ansible_distribution_version }}

  tasks:
    # ========== SYSTEM ==========

    - name: Update APT cache
      apt:
        update_cache: yes
        cache_valid_time: 3600

    - name: Install Nginx
      apt:
        name: nginx
        state: present

    - name: Install curl (for health checks)
      apt:
        name: curl
        state: present

    # ========== DIRECTORIES ==========

    - name: Create application directory
      file:
        path: "{{ app_dir }}"
        state: directory
        owner: "{{ app_user }}"
        group: "{{ app_user }}"
        mode: '0755'

    # ========== DEPLOY APPLICATION ==========

    - name: Deploy index.html
      copy:
        content: |
          <!DOCTYPE html>
          <html lang="fr">
          <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>TechNova - Phase 2</title>
            <style>
              * {
                margin: 0;
                padding: 0;
                box-sizing: border-box;
              }
              body {
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                min-height: 100vh;
                display: flex;
                justify-content: center;
                align-items: center;
                padding: 20px;
              }
              .container {
                background: white;
                border-radius: 10px;
                box-shadow: 0 20px 60px rgba(0,0,0,0.3);
                padding: 40px;
                max-width: 600px;
                text-align: center;
              }
              h1 {
                color: #333;
                margin-bottom: 20px;
              }
              .info-box {
                background: #f8f9fa;
                border-left: 4px solid #667eea;
                padding: 20px;
                margin: 20px 0;
                text-align: left;
                border-radius: 5px;
              }
              .label {
                font-weight: bold;
                color: #667eea;
              }
              .badge {
                display: inline-block;
                background: #667eea;
                color: white;
                padding: 5px 15px;
                border-radius: 20px;
                font-size: 0.9em;
                margin-top: 20px;
              }
            </style>
          </head>
          <body>
            <div class="container">
              <h1>üöÄ TechNova Phase 2</h1>
              <h2 style="color: #666; font-size: 1.1em; margin-bottom: 30px;">Infrastructure as Code</h2>
              
              <div class="info-box">
                <p><span class="label">Serveur :</span> {{ ansible_hostname }}</p>
                <p><span class="label">IP Priv√©e :</span> {{ ansible_default_ipv4.address }}</p>
                <p><span class="label">OS :</span> {{ ansible_distribution }} {{ ansible_distribution_version }}</p>
              </div>

              <p style="margin-top: 30px; color: #666;">
                Cette page a √©t√© d√©ploy√©e automatiquement avec Terraform + Ansible
              </p>
              <span class="badge">‚úì Nginx est op√©rationnel</span>
            </div>
          </body>
          </html>
        dest: "{{ app_dir }}/index.html"
        owner: "{{ app_user }}"
        group: "{{ app_user }}"
        mode: '0644'
      notify: restart nginx

    # ========== NGINX CONFIG ==========

    - name: Deploy Nginx configuration
      template:
        src: nginx.conf.j2
        dest: /etc/nginx/sites-available/devcloud
        owner: root
        group: root
        mode: '0644'
        backup: yes
      notify: restart nginx

    - name: Enable devcloud site
      file:
        src: /etc/nginx/sites-available/devcloud
        dest: /etc/nginx/sites-enabled/devcloud
        state: link
        force: yes
      notify: restart nginx

    - name: Disable default site
      file:
        path: /etc/nginx/sites-enabled/default
        state: absent
      notify: restart nginx

    # ========== SERVICES ==========

    - name: Start and enable Nginx
      systemd:
        name: nginx
        state: started
        enabled: yes
        daemon_reload: yes

    # ========== HEALTH CHECKS ==========

    - name: Wait for Nginx to be ready
      wait_for:
        port: "{{ nginx_port }}"
        delay: 2
        timeout: 10

    - name: Test HTTP response
      uri:
        url: "http://localhost:{{ nginx_port }}/index.html"
        status_code: 200
      register: http_test
      retries: 3
      delay: 2

    - name: Display health check result
      debug:
        msg: |
          ‚úì Health check PASSED
          Status: {{ http_test.status }}
          URL: http://{{ inventory_hostname }}/index.html

  handlers:
    - name: restart nginx
      systemd:
        name: nginx
        state: restarted
        daemon_reload: yes

  post_tasks:
    - name: Deployment summary
      debug:
        msg: |
          ‚úÖ D√©ploiement r√©ussi !
          
          Acc√©dez √† : http://{{ ansible_default_ipv4.address }}/index.html
          SSH : ssh -i ~/.ssh/id_rsa ubuntu@{{ ansible_default_ipv4.address }}
EOF

# 3b. V√©rifier syntaxe
ansible-playbook -i hosts.ini playbook.yml --syntax-check

# Output attendu : playbook.yml is valid
```

**Checkpoint 3 ‚úì**
```bash
# Syntaxe correcte
```

### √âtape 4 : Cr√©er Template Jinja2 (10 min)

```bash
# 4a. Cr√©er nginx.conf.j2
cat > nginx.conf.j2 << 'EOF'
# Nginx configuration for TechNova
# Generated by Ansible

server {
    listen {{ nginx_port }} default_server;
    listen [::]:{{ nginx_port }} default_server;

    server_name _;

    # Compression
    gzip on;
    gzip_types text/plain text/css text/javascript application/json;
    gzip_vary on;

    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;

    # Root directory
    root {{ app_dir }};
    index index.html;

    # Main location
    location / {
        try_files $uri $uri/ =404;
    }

    # Health check endpoint
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }

    # Deny hidden files
    location ~ /\. {
        deny all;
        access_log off;
        log_not_found off;
    }

    # Logging
    access_log /var/log/nginx/devcloud_access.log combined buffer=32k;
    error_log /var/log/nginx/devcloud_error.log warn;
}
EOF

# 4b. V√©rifier fichier
cat nginx.conf.j2
```

**Checkpoint 4 ‚úì**
```bash
# V√©rifier pr√©sence du fichier
ls -la nginx.conf.j2
```

### √âtape 5 : Dry-Run (Test sans Modifier) (5 min)

```bash
# 5a. Tester le playbook en mode check (dry-run)
ansible-playbook -i hosts.ini playbook.yml --check

# Output attendu :
# TASK [Update APT cache] *****
# changed: [web-technova-1]
# changed: [web-technova-2]
# ...
#
# PLAY RECAP *******************
# web-technova-1 : ok=X changed=Y unreachable=0 failed=0
# web-technova-2 : ok=X changed=Y unreachable=0 failed=0

# Remarque : "changed" car c'est un dry-run. En r√©el, √ßa sera different.
```

### √âtape 6 : Ex√©cuter le Playbook (25 min)

```bash
# 6a. EX√âCUTER POUR VRAI
ansible-playbook -i hosts.ini playbook.yml -v

# Output attendu :
# PLAY [Configure web servers with Nginx] ***
# TASK [Display deployment info] *****
# ok: [web-technova-1] => {
#     "msg": "D√©ploiement vers web-technova-1..."
# }
# TASK [Update APT cache] *****
# changed: [web-technova-1]
# changed: [web-technova-2]
# ...
# TASK [Test HTTP response] *****
# ok: [web-technova-1]
# ok: [web-technova-2]
# ...
# PLAY RECAP ***
# web-technova-1 : ok=13 changed=4 unreachable=0 failed=0
# web-technova-2 : ok=13 changed=4 unreachable=0 failed=0

# ‚è±Ô∏è Temps attendu : 10-15 minutes

# Sauvegardez ce r√©sultat !
ansible-playbook -i hosts.ini playbook.yml -v > playbook_execution.log 2>&1
```

**Checkpoint 6 ‚úì**
```bash
# V√©rifier succ√®s
grep "unreachable=0 failed=0" playbook_execution.log
```

### √âtape 7 : Valider Infrastructure (15 min)

```bash
# 7a. Obtenir IPs
cd ../terraform
WEB1=$(terraform output -json instance_ips | jq -r 'to_entries[0].value')
WEB2=$(terraform output -json instance_ips | jq -r 'to_entries[1].value')

echo "Web 1 : $WEB1"
echo "Web 2 : $WEB2"

# 7b. Tester avec curl
echo "Test serveur 1 :"
curl -s http://$WEB1/index.html | head -20

echo ""
echo "Test serveur 2 :"
curl -s http://$WEB2/index.html | head -20

# 7c. Tester health check
echo ""
echo "Health checks :"
curl -s http://$WEB1/health
curl -s http://$WEB2/health

# 7d. Depuis navigateur (optionnel)
echo ""
echo "Ouvrez dans votre navigateur :"
echo "  - http://$WEB1"
echo "  - http://$WEB2"
```

### √âtape 8 : Capturer R√©sultats (5 min)

```bash
# 8a. Logs de d√©ploiement
ansible-playbook -i ../ansible/hosts.ini ../ansible/playbook.yml > deployment_log.txt 2>&1

# 8b. Test de connectivit√©
ansible -i ../ansible/hosts.ini all -m command -a "nginx -v" > nginx_versions.txt

# 8c. V√©rifier pages HTML
curl http://$WEB1 > server1.html
curl http://$WEB2 > server2.html

# 8d. R√©sum√©
cat > ../DEPLOYMENT_SUMMARY.md << 'EOF'
# TechNova Phase 2 - D√©ploiement R√©ussi ‚úÖ

## Infrastructure (Terraform)
- VPC : vpc-XXXXX (10.0.0.0/16)
- Instances : 2 x t3.micro (Free Tier)
- Security Group : SSH (22) + HTTP (80)

## Configuration (Ansible)
- Nginx install√© et d√©marr√©
- Pages HTML d√©ploy√©es
- Health checks fonctionnels

## IPs Publiques
- Web 1 : $(echo $WEB1)
- Web 2 : $(echo $WEB2)

## V√©rification
- SSH : ‚úì Fonctionnel
- HTTP : ‚úì Pages accessible
- Health : ‚úì R√©ponses positives

## Prochaines √©tapes
1. Nettoyer avec `terraform destroy`
2. Archiver logs
3. Valider pour Module 4
EOF

cat ../DEPLOYMENT_SUMMARY.md
```

### ‚úÖ Livrables TP3.2

- [ ] Playbook Ansible cr√©√© (playbook.yml)
- [ ] Template Nginx cr√©√© (nginx.conf.j2)
- [ ] Inventaire Ansible g√©n√©r√© (hosts.ini)
- [ ] Ex√©cution sans erreurs (logs captur√©s)
- [ ] 2 serveurs avec Nginx en cours d'ex√©cution
- [ ] Pages HTML accessibles depuis navigateur
- [ ] Health checks r√©ussis
- [ ] Captures d'√©cran ou fichiers logs

---

## √âVALUATION & RUBRICS 

### Grille d'√âvaluation TP3.1 : Terraform (/20)

| Crit√®re | Points | Validation |
|---------|--------|------------|
| **Code Terraform syntaxiquement correct** | 3 | `terraform validate` = Success |
| **VPC + Subnet cr√©√©s** | 2 | Terraform state contient aws_vpc + aws_subnet |
| **Internet Gateway + Route Table** | 2 | IGW attach√©, routes configur√©es |
| **Security Group (SSH + HTTP)** | 2 | Ports 22 et 80 autoris√©s |
| **2 instances EC2 t3.micro** | 3 | Instances cr√©√©es avec count=2 |
| **Outputs configur√©s** | 2 | terraform output affiche IPs publiques |
| **SSH fonctionnel** | 2 | Connexion SSH r√©ussie vers une instance |
| **Destruction compl√®te** | 2 | `terraform destroy` supprime tout sans erreurs |
| **Documentation / Commentaires** | 1 | Code comment√© et lisible |
| **Gestion d'erreurs** | 1 | Handling validations + depends_on |

**Total TP3.1 : /20**  

---

### Grille d'√âvaluation TP3.2 : Ansible (/20)

| Crit√®re                             | Points | Validation                               |
| ----------------------------------- | ------ | ---------------------------------------- |
| **Inventaire g√©n√©r√© correctement**  | 2      | hosts.ini contient IPs et variables      |
| **Connectivit√© Ansible (ping)**     | 2      | `ansible all -m ping` = SUCCESS          |
| **Playbook syntaxiquement correct** | 2      | `--syntax-check` = valid                 |
| **Nginx install√© + d√©marr√©**        | 3      | `systemctl status nginx` = active        |
| **Pages HTML d√©ploy√©es**            | 2      | Pages accessibles avec curl              |
| **Template Jinja2 fonctionnel**     | 2      | Configuration Nginx g√©n√©r√©e correctement |
| **Health checks r√©ussis**           | 2      | `uri` module retourne 200 OK             |
| **Handlers fonctionnels**           | 2      | Nginx red√©marr√© lors des changements     |
| **Logs + Documentation**            | 2      | Logs de d√©ploiement captur√©s             |
| **Tests finaux**                    | 1      | Pages HTML accessibles depuis navigateur |

**Total TP3.2 : /20**  

---
## D√âPANNAGE RAPIDE 

### Erreurs Terraform Courantes

| Erreur | Cause | Solution |
|--------|-------|----------|
| `Provider hashicorp/aws not found` | Init non compl√©t√©e | Lancer `terraform init` |
| `state locked` | TP pr√©c√©dent non nettoy√© | `terraform force-unlock <ID>` ou attendre |
| `CIDR already in use` | VPC avec m√™me CIDR existe | Changer CIDR (ex: 10.1.0.0/16) |
| `Key not found` | Chemin cl√© SSH incorrect | V√©rifier : `ls ~/.ssh/id_rsa.pub` |
| `instance unreachable` | SG bloque port 22 | V√©rifier Security Group (SSH=22) |
| `invalid resource name` | Caract√®res invalides (-) | Utiliser _ (ex: sg_web au lieu de sg-web) |

### Erreurs Ansible Courantes

| Erreur | Cause | Solution |
|--------|-------|----------|
| `unreachable` | SSH √©choue | V√©rifier SG, cl√© SSH, instances d√©marr√©es |
| `permission denied` | Besoin sudo | Ajouter `become: yes` dans playbook |
| `host not found` | Inventory incorrect | V√©rifier hosts.ini (IPs, user) |
| `module not found` | Module Ansible manquant | V√©rifier spelling (apt vs aptget) |
| `template not found` | Path relatif incorrect | V√©rifier chemin (nginx.conf.j2 au m√™me niveau) |

### Commandes Debug Utiles

```bash
# ========== TERRAFORM ==========

# Lister toutes ressources
terraform state list

# Afficher d√©tails d'une ressource
terraform state show aws_instance.web[0]

# Formater automatiquement le code
terraform fmt -recursive

# G√©n√©rer graphe d√©pendances (PNG)
terraform graph | dot -Tpng > graph.png

# ========== ANSIBLE ==========

# Afficher inventory d√©taill√©
ansible-inventory -i hosts.ini --list | jq .

# R√©cup√©rer informations syst√®me
ansible all -i hosts.ini -m setup | head -100

# Ultra verbose pour d√©boguer
ansible-playbook -i hosts.ini playbook.yml -vvv

# Ex√©cuter ad-hoc (commande unique)
ansible all -i hosts.ini -m command -a "systemctl status nginx"

# Tester template avant d√©ploiement
ansible all -i hosts.ini -m template -a "src=nginx.conf.j2 dest=/tmp/test.conf" --check
```

### Probl√®mes Courants & Solutions

**Probl√®me : Instances sont cr√©√©es mais pas accessibles en SSH**

```bash
# Causes possibles :
# 1. Instance encore en d√©marrage (attendre 30s)
# 2. Security Group bloque port 22
# 3. Cl√© SSH locale n'existe pas

# Solutions :
sleep 30  # Attendre
terraform show | grep "security_groups"  # V√©rifier SG
ls -la ~/.ssh/id_rsa  # V√©rifier cl√©

# Test manuel SSH avec verbose
ssh -v -i ~/.ssh/id_rsa ubuntu@IP
```

**Probl√®me : Ansible pas de ping r√©ponse**

```bash
# Cause : Instances pas totalement d√©marr√©es
sleep 60
ansible -i hosts.ini all -m ping

# Alternative : tester SSH directement
ssh -i ~/.ssh/id_rsa ubuntu@IP "echo 'OK'"
```

**Probl√®me : Nginx n'acc√©pte pas la configuration**

```bash
# Valider syntaxe Nginx
nginx -t  # √Ä lancer dans l'instance

# Via Ansible
ansible all -i hosts.ini -b -m command -a "nginx -t"

# Voir logs
ansible all -i hosts.ini -b -m command -a "tail -20 /var/log/nginx/error.log"
```

**Probl√®me : Pages HTML ne s'affichent pas**

```bash
# V√©rifier permissions fichiers
ansible all -i hosts.ini -b -m command -a "ls -la /var/www/devcloud"

# V√©rifier logs Nginx
ansible all -i hosts.ini -b -m command -a "tail /var/log/nginx/access.log"

# Tester depuis l'instance
ansible all -i hosts.ini -m command -a "curl -s http://localhost/index.html"
```

---

## Checklist Finale Avant Validation

### Avant TP3.1

- [ ] Terraform install√© (version >= 1.0)
- [ ] Cl√© SSH g√©n√©r√©e (~/.ssh/id_rsa.pub existe)
- [ ] AWS credentials configur√©es
- [ ] Compte AWS avec free tier disponible

### Apr√®s TP3.1

- [ ] 8 ressources cr√©√©es (terraform state list)
- [ ] SSH fonctionnel vers au moins une instance
- [ ] Outputs affich√©s (IPs publiques)
- [ ] hosts.ini g√©n√©r√©

### Apr√®s TP3.2

- [ ] Playbook ex√©cut√© sans erreurs
- [ ] Nginx actif (systemctl status = active)
- [ ] Pages HTML accessibles (curl 200 OK)
- [ ] Health checks r√©ussis

### Avant Nettoyage

- [ ] Logs de d√©ploiement sauvegard√©s
- [ ] Screenshots captur√©es
- [ ] README.md document√©
- [ ] terraform destroy pr√™t

